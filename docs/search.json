[
  {
    "objectID": "reproducible_documents.html",
    "href": "reproducible_documents.html",
    "title": "Reproducible Documents",
    "section": "",
    "text": "Traditional workflows within science use many different kinds of tools. This requires careful recording of what happens at each step of the scientific process. Good laboratory notebook practices are a feature of many sciences but are not typically taught as part of a psychology curriculum. This combination within psychology of a lack of clear recording of data collection and analysis practices can lead to difficulties in retracing the steps that led to any given outcome in science. A traditional workflow in psychology may involve the design of research and preparation for ethical review using a word processor and perhaps some diagramming tools. This is followed by data collection on a different platform perhaps using pen and paper in a laboratory, but increasingly using automated platforms such as Qualtrics, PsychoPy, or jsPsych. Following this, data is manipulated from the form and shape it arrives in from whatever platform is being used and is then wrangled into the right shape for analysis sometimes in a statistical program, but often using cut and paste techniques in Microsoft Excel or a similar spreadsheet program. The data is then analysed using some statistical software platform such SPSS, SAS, JASP, Jamovi or R. When the results are found these are extracted and the whole sequence is written up using some combination of a word processor—typically Microsoft Word—and perhaps some citation software such as Endnote or RefWorks.\nThe problem with this approach is that it is not very reproducible, the steps are difficult to trace unless the researcher is inordinately meticulous with their recording and consequently this approach is prone to untraceable errors.\nThe solution is to create a reproducible document.\n\n\n\nReproducible documents are a way of eliminating as many of these disparate steps as possible and maximising the recording of the steps that are taken along the research process. The goal is to streamline the research process while making it more transparent and reproducible. Ideally these documents will be made available for the scrutiny of other scientific researchers and the public. However, there are many additional advantages to using reproducible documents as they make the process of conducting science more efficient. They make research much easier to pick up after the inevitable six month to year hiatuses that occur throughout the scientific process as projects go through their different stages and the myriad competing attention drawing factors of a professional researchers life that fragment our time.\nWe are not yet at a stage where all of the various platforms and processes can be accumulated into one work flow but we can do much better than the traditional approach.\nTypically a reproducible document is a combination of some word processing tools to create the document with mechanisms to insert computer code chunks that allow us to load, store, and manipulate data; conduct statistical and mathematical analysis; visualise the analysis producing tables and plots as part of the document output; and integrating with citation software to allow the easy creation of references.\n\n\n\n\n\nThere are a range of preexisting computational technologies that can be brought together to enable these documents. The TeX and LaTeX systems are well established document preparation and typesetting systems (latex-project); there is a new system with similar goals called Typst. These systems are aided by the use of Markdown (markdownguide.org) which provides a very simple document markup language—a way of writing plain text documents with simple formatting instructions—which the researcher uses to create the documents. A final technology is pandoc (pandoc.org) which allows the same markdown document to be output to many different formats. One markdown document can be used to create websites, PDFs, Word documents, ePub books and many more. These represent the word processing part, these are put together in a reproducible document with bits of code that can be part of producing images or diagrams in the document or may be code that contains the statistical analysis and output. These bit of code are contained in code chunks.\n\n\n\nThe computer chunks are comprised of various different languages that can be mixed and matched, the most commonly used languages are R and Python, but languages like Julia, Stan, Javascript, SQL, C, and Fortran.\nThe current document is being written as a reproducible document using the RStudio software and I can include a code chunk in R\n\ndata &lt;- c(1,2,3,4,5,6,7,8,9,10)\nx &lt;- mean(data)\nprint(x)\n\n[1] 5.5\n\n\nor in python\n\nimport statistics\ndata = [1,2,3,4,5,6,7,8,9,10]\nx = statistics.mean(data)\nprint(x)\n\n5.5\n\n\nCode chunks can be hidden and only the output produced which is useful when including any data wrangling code that you do not want to be seen in a finished output, of for creating tables and plots. The important thing is that the code remains visible in the source form of the document so it can be inspected if necessary and it stays in the one place with the end product document. You can see this process at work in Figure 1, which contains code included in the source document but hidden in the final document.\n\n\n\n\n\n\n\n\nFigure 1: Temperature and ozone level.\n\n\n\n\n\n\n\n\nCitation management and the automatic creation of a references section are important components of reproducible document systems. Most systems interact with pandoc, BibTeX, Zotero, Crossref, PubMed, and the DOI system to allow in text citations with automated References sections (e.g. McKeown, 2013). This reference will appear in the References section automatically without any more work.\n\n\n\nAn important but optional companion technology to the creation of reproducible documents is version control software such as git or svn. Git is the currently most popular type of version control. Version control systems were developed to keep track of the various changes that were made to computer code and to allow variations of code to be made and merged into a single document and to allow collaboration by multiple coders without the danger of overwriting each other. This turns out to be handy when it comes to writing documents too, especially documents that contain code. Think of version control as a high powered and rigorous combination of “track changes” and backing up files. It is a solution to folders full of final final final versions of the same document. Git is a piece of software that sits on your local computer and controls the versions of your documents, but it has a companion in github that offers remote hosting of documents and enables collaboration between multiple contributors. You can see the code for this document at (github.com/QUBPsy/QUBPsyOpenScience).\n\n\n\n\nThere are a variety of ways of creating reproducible documents. Here we will look at some of the options.\n\n\nOne of the two major pioneers of mechanisms to produce reproducible documents came from the combination of the R focused Integrated Development Environment (IDE) RStudio. RStudio started in 2011 to create an easy environment in which to write R code and install and manage R packages. In 2012 Yihui Xie introduced the knitr package to enable the creation of documents with code chunks embedded in them. Markdown become the most popular language to develop these documents and the rmarkdown package was introduced in 2014, and it became well embedded within the RStudio IDE where a lot of effort was made to make the production of RMarkdown documents simple and easy. The kinds of documents that could be produced in RMarkdown, webpages and websites, pdf documents, Shiny web apps, journal articles, slides and presentations, and books.\nThe R Markdown ecosystem is now quite mature and there are many packages that allow people to get up and running with many different aspects such as: the creation of quite sophisticated websites using RStudio and Github pages (with many other options); the creation of APA style manuscripts and journal articles using papaja (although this remains somewhat buggy); templates to aid in the creation of many different kinds of journal articles through rticles such as Elsevier, IEEE, Royal Society, Springer, PNAS journal templates (Table 1 provides a full list of journal abbreviations); full book creation in online, pdf and ePub formats using bookdown (see an example here); various kinds of presentations (Powerpoint, Beamer, Slidy); dashboards using the flexdashboard package; and interactive documents incorporating Shiny web apps and html widgets.\n\n\n\n\nTable 1: The abbreviations for the R Markdown journal article templates avaialble in the rticles R package.\n\n\n\n\n\n\nacm\nfrontiers\noup_v0\n\n\nacs\nglossa\noup_v1\n\n\naea\nieee\npeerj\n\n\nagu\nims\npihph\n\n\najs\ninforms\nplos\n\n\namq\niop\npnas\n\n\nams\nisba\nrjournal\n\n\narxiv\njasa\nrsos\n\n\nasa\njedm\nrss\n\n\nbioinformatics\njoss\nsage\n\n\nbiometrics\njss\nsim\n\n\ncopernicus\nlipics\nspringer\n\n\nctex\nlncs\ntf\n\n\nelsevier\nmdpi\ntrb\n\n\n\n\n\n\n\n\nOne issue that arises with reproducible documents arises due to their instrinsic nature; they contain code. Code depends on other code and code changes with time. There are constant updates to packages and software and often these updates will break older code as functions become deprecated or change in nature. The solution to this problem is to create environments in which to encapsulate code and its dependencies. In R the Packrat and newer renv packages are designed to provide this dependency management within R. These packages will create a local environment snapshot of all the necessary code and allow them to reloaded whent he time comes to work with the files. An example of a reproducible document that uses renv to do this can be found at this github repository which provided the code to produce and run all the experiments need to produce this paper (Dupré et al., 2020).\n\n\n\nAnother option for creating reproducible documents that has its origins in the Python computer language ecosystem is Jupyter Notebooks. Typically these require knowledge of the Python programming language and comfort working in a command line environment such as terminals in Unix environments and Windows Terminal in Windows 10 and above (previously the Windows Console).\nA Jupyter Notebook is a reproducible document that normally sits in a folder on your computer and you interact with using an interface in your browser. You navigate to the appropriate folder in your terminal and type “jupyter notebook” and this opens your browser and browser window that allows you to interact with the document. Documents contain a mix of text and code. The is a classic Jupyter Notebook interface and a more advanced IDE style interface known as JupyterLab. There are online servers that will allow you to interact with Jupyter Notebooks without the need to install software and have a dedicated machine, some of these can be seen at the Jupyter project: classic interface, JupyterLab interface. Similarly to RStudio even though they started firmly focused on one language—Python—but they also realised the value in supporting multiple languages and allowing them to be used interchangeably, they now support about 40 languages including R (R in a Jupyter Notebook).\nDependency issues in Python can be dealt with in a similar way to R by creating environments in which the code and packages can be isolated from other environments. The use of virtual environments in Python is more well established than in R and there are a variety of ways to create them. For example, the venv module, the virtualenv package, or within the Anaconda Python distribution platform. Virtual environments are often advised as best practice within general Python usage.\n\n\n\nThe two previous reproducible document approaches showed a trend from focusing on a single language towards reproducible documents that are more flexible. Recently the people at RStudio have announced that they have taken this a step further with the development of Quarto, Quarto is a reproducible document system again built on Pandoc allowing documents to be created using Markdown or Jupyter Notebooks. Quarto is installed independently of the other systems as separate software on the computer and then each of the systems interface with it. Reproducible documents can then be created in a text editor, RStudio, Jupyter Notebooks or VS Code (Microsoft’s Visual Studio Code IDE). The goal is to make the document production part of the system agnostic to the way in which people prefer to work. As it is being spearheaded by Posit the company that make and control the RStudio IDE it is likely to supersede the current R Markdown ecosystem (although R Markdown will be around for a long time). I would advise anyone starting this with reproducible documents to look first at Quarto as it is already quite mature and is under very active development. In producing Quarto the Rstudio team have taken the opportunity to make some of the issues that existed with R Markdown better and they seek to make a more unified system for developing each of the different styles of output. I expect that it will quickly become the standard within the R ecosystem at least if it that is not already the case. This current book/website hybrid has been created using Quarto, although it’s very first incarnation was as a R Markdown Bookdown project.\n\n\n\nMicrosoft’s Visual Studio Code is an IDE that is used by many people who do development within the Windows ecosystem. With the arrival of Quarto it can now be used as an environment for developing reproducible documents. It requires the addition of a Code Extension. This may be useful if you are already a user of VS Code otherwise the Rstudio IDE is probably a better place to start."
  },
  {
    "objectID": "reproducible_documents.html#why-do-we-need-reproducible-documents",
    "href": "reproducible_documents.html#why-do-we-need-reproducible-documents",
    "title": "Reproducible Documents",
    "section": "",
    "text": "Traditional workflows within science use many different kinds of tools. This requires careful recording of what happens at each step of the scientific process. Good laboratory notebook practices are a feature of many sciences but are not typically taught as part of a psychology curriculum. This combination within psychology of a lack of clear recording of data collection and analysis practices can lead to difficulties in retracing the steps that led to any given outcome in science. A traditional workflow in psychology may involve the design of research and preparation for ethical review using a word processor and perhaps some diagramming tools. This is followed by data collection on a different platform perhaps using pen and paper in a laboratory, but increasingly using automated platforms such as Qualtrics, PsychoPy, or jsPsych. Following this, data is manipulated from the form and shape it arrives in from whatever platform is being used and is then wrangled into the right shape for analysis sometimes in a statistical program, but often using cut and paste techniques in Microsoft Excel or a similar spreadsheet program. The data is then analysed using some statistical software platform such SPSS, SAS, JASP, Jamovi or R. When the results are found these are extracted and the whole sequence is written up using some combination of a word processor—typically Microsoft Word—and perhaps some citation software such as Endnote or RefWorks.\nThe problem with this approach is that it is not very reproducible, the steps are difficult to trace unless the researcher is inordinately meticulous with their recording and consequently this approach is prone to untraceable errors.\nThe solution is to create a reproducible document."
  },
  {
    "objectID": "reproducible_documents.html#what-are-reproducible-documents",
    "href": "reproducible_documents.html#what-are-reproducible-documents",
    "title": "Reproducible Documents",
    "section": "",
    "text": "Reproducible documents are a way of eliminating as many of these disparate steps as possible and maximising the recording of the steps that are taken along the research process. The goal is to streamline the research process while making it more transparent and reproducible. Ideally these documents will be made available for the scrutiny of other scientific researchers and the public. However, there are many additional advantages to using reproducible documents as they make the process of conducting science more efficient. They make research much easier to pick up after the inevitable six month to year hiatuses that occur throughout the scientific process as projects go through their different stages and the myriad competing attention drawing factors of a professional researchers life that fragment our time.\nWe are not yet at a stage where all of the various platforms and processes can be accumulated into one work flow but we can do much better than the traditional approach.\nTypically a reproducible document is a combination of some word processing tools to create the document with mechanisms to insert computer code chunks that allow us to load, store, and manipulate data; conduct statistical and mathematical analysis; visualise the analysis producing tables and plots as part of the document output; and integrating with citation software to allow the easy creation of references."
  },
  {
    "objectID": "reproducible_documents.html#the-tools-of-reproducible-documents",
    "href": "reproducible_documents.html#the-tools-of-reproducible-documents",
    "title": "Reproducible Documents",
    "section": "",
    "text": "There are a range of preexisting computational technologies that can be brought together to enable these documents. The TeX and LaTeX systems are well established document preparation and typesetting systems (latex-project); there is a new system with similar goals called Typst. These systems are aided by the use of Markdown (markdownguide.org) which provides a very simple document markup language—a way of writing plain text documents with simple formatting instructions—which the researcher uses to create the documents. A final technology is pandoc (pandoc.org) which allows the same markdown document to be output to many different formats. One markdown document can be used to create websites, PDFs, Word documents, ePub books and many more. These represent the word processing part, these are put together in a reproducible document with bits of code that can be part of producing images or diagrams in the document or may be code that contains the statistical analysis and output. These bit of code are contained in code chunks.\n\n\n\nThe computer chunks are comprised of various different languages that can be mixed and matched, the most commonly used languages are R and Python, but languages like Julia, Stan, Javascript, SQL, C, and Fortran.\nThe current document is being written as a reproducible document using the RStudio software and I can include a code chunk in R\n\ndata &lt;- c(1,2,3,4,5,6,7,8,9,10)\nx &lt;- mean(data)\nprint(x)\n\n[1] 5.5\n\n\nor in python\n\nimport statistics\ndata = [1,2,3,4,5,6,7,8,9,10]\nx = statistics.mean(data)\nprint(x)\n\n5.5\n\n\nCode chunks can be hidden and only the output produced which is useful when including any data wrangling code that you do not want to be seen in a finished output, of for creating tables and plots. The important thing is that the code remains visible in the source form of the document so it can be inspected if necessary and it stays in the one place with the end product document. You can see this process at work in Figure 1, which contains code included in the source document but hidden in the final document.\n\n\n\n\n\n\n\n\nFigure 1: Temperature and ozone level.\n\n\n\n\n\n\n\n\nCitation management and the automatic creation of a references section are important components of reproducible document systems. Most systems interact with pandoc, BibTeX, Zotero, Crossref, PubMed, and the DOI system to allow in text citations with automated References sections (e.g. McKeown, 2013). This reference will appear in the References section automatically without any more work.\n\n\n\nAn important but optional companion technology to the creation of reproducible documents is version control software such as git or svn. Git is the currently most popular type of version control. Version control systems were developed to keep track of the various changes that were made to computer code and to allow variations of code to be made and merged into a single document and to allow collaboration by multiple coders without the danger of overwriting each other. This turns out to be handy when it comes to writing documents too, especially documents that contain code. Think of version control as a high powered and rigorous combination of “track changes” and backing up files. It is a solution to folders full of final final final versions of the same document. Git is a piece of software that sits on your local computer and controls the versions of your documents, but it has a companion in github that offers remote hosting of documents and enables collaboration between multiple contributors. You can see the code for this document at (github.com/QUBPsy/QUBPsyOpenScience)."
  },
  {
    "objectID": "reproducible_documents.html#reproducible-document-platforms",
    "href": "reproducible_documents.html#reproducible-document-platforms",
    "title": "Reproducible Documents",
    "section": "",
    "text": "There are a variety of ways of creating reproducible documents. Here we will look at some of the options.\n\n\nOne of the two major pioneers of mechanisms to produce reproducible documents came from the combination of the R focused Integrated Development Environment (IDE) RStudio. RStudio started in 2011 to create an easy environment in which to write R code and install and manage R packages. In 2012 Yihui Xie introduced the knitr package to enable the creation of documents with code chunks embedded in them. Markdown become the most popular language to develop these documents and the rmarkdown package was introduced in 2014, and it became well embedded within the RStudio IDE where a lot of effort was made to make the production of RMarkdown documents simple and easy. The kinds of documents that could be produced in RMarkdown, webpages and websites, pdf documents, Shiny web apps, journal articles, slides and presentations, and books.\nThe R Markdown ecosystem is now quite mature and there are many packages that allow people to get up and running with many different aspects such as: the creation of quite sophisticated websites using RStudio and Github pages (with many other options); the creation of APA style manuscripts and journal articles using papaja (although this remains somewhat buggy); templates to aid in the creation of many different kinds of journal articles through rticles such as Elsevier, IEEE, Royal Society, Springer, PNAS journal templates (Table 1 provides a full list of journal abbreviations); full book creation in online, pdf and ePub formats using bookdown (see an example here); various kinds of presentations (Powerpoint, Beamer, Slidy); dashboards using the flexdashboard package; and interactive documents incorporating Shiny web apps and html widgets.\n\n\n\n\nTable 1: The abbreviations for the R Markdown journal article templates avaialble in the rticles R package.\n\n\n\n\n\n\nacm\nfrontiers\noup_v0\n\n\nacs\nglossa\noup_v1\n\n\naea\nieee\npeerj\n\n\nagu\nims\npihph\n\n\najs\ninforms\nplos\n\n\namq\niop\npnas\n\n\nams\nisba\nrjournal\n\n\narxiv\njasa\nrsos\n\n\nasa\njedm\nrss\n\n\nbioinformatics\njoss\nsage\n\n\nbiometrics\njss\nsim\n\n\ncopernicus\nlipics\nspringer\n\n\nctex\nlncs\ntf\n\n\nelsevier\nmdpi\ntrb\n\n\n\n\n\n\n\n\nOne issue that arises with reproducible documents arises due to their instrinsic nature; they contain code. Code depends on other code and code changes with time. There are constant updates to packages and software and often these updates will break older code as functions become deprecated or change in nature. The solution to this problem is to create environments in which to encapsulate code and its dependencies. In R the Packrat and newer renv packages are designed to provide this dependency management within R. These packages will create a local environment snapshot of all the necessary code and allow them to reloaded whent he time comes to work with the files. An example of a reproducible document that uses renv to do this can be found at this github repository which provided the code to produce and run all the experiments need to produce this paper (Dupré et al., 2020).\n\n\n\nAnother option for creating reproducible documents that has its origins in the Python computer language ecosystem is Jupyter Notebooks. Typically these require knowledge of the Python programming language and comfort working in a command line environment such as terminals in Unix environments and Windows Terminal in Windows 10 and above (previously the Windows Console).\nA Jupyter Notebook is a reproducible document that normally sits in a folder on your computer and you interact with using an interface in your browser. You navigate to the appropriate folder in your terminal and type “jupyter notebook” and this opens your browser and browser window that allows you to interact with the document. Documents contain a mix of text and code. The is a classic Jupyter Notebook interface and a more advanced IDE style interface known as JupyterLab. There are online servers that will allow you to interact with Jupyter Notebooks without the need to install software and have a dedicated machine, some of these can be seen at the Jupyter project: classic interface, JupyterLab interface. Similarly to RStudio even though they started firmly focused on one language—Python—but they also realised the value in supporting multiple languages and allowing them to be used interchangeably, they now support about 40 languages including R (R in a Jupyter Notebook).\nDependency issues in Python can be dealt with in a similar way to R by creating environments in which the code and packages can be isolated from other environments. The use of virtual environments in Python is more well established than in R and there are a variety of ways to create them. For example, the venv module, the virtualenv package, or within the Anaconda Python distribution platform. Virtual environments are often advised as best practice within general Python usage.\n\n\n\nThe two previous reproducible document approaches showed a trend from focusing on a single language towards reproducible documents that are more flexible. Recently the people at RStudio have announced that they have taken this a step further with the development of Quarto, Quarto is a reproducible document system again built on Pandoc allowing documents to be created using Markdown or Jupyter Notebooks. Quarto is installed independently of the other systems as separate software on the computer and then each of the systems interface with it. Reproducible documents can then be created in a text editor, RStudio, Jupyter Notebooks or VS Code (Microsoft’s Visual Studio Code IDE). The goal is to make the document production part of the system agnostic to the way in which people prefer to work. As it is being spearheaded by Posit the company that make and control the RStudio IDE it is likely to supersede the current R Markdown ecosystem (although R Markdown will be around for a long time). I would advise anyone starting this with reproducible documents to look first at Quarto as it is already quite mature and is under very active development. In producing Quarto the Rstudio team have taken the opportunity to make some of the issues that existed with R Markdown better and they seek to make a more unified system for developing each of the different styles of output. I expect that it will quickly become the standard within the R ecosystem at least if it that is not already the case. This current book/website hybrid has been created using Quarto, although it’s very first incarnation was as a R Markdown Bookdown project.\n\n\n\nMicrosoft’s Visual Studio Code is an IDE that is used by many people who do development within the Windows ecosystem. With the arrival of Quarto it can now be used as an environment for developing reproducible documents. It requires the addition of a Code Extension. This may be useful if you are already a user of VS Code otherwise the Rstudio IDE is probably a better place to start."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "Tutorial-Git, Github, and RStudio.html",
    "href": "Tutorial-Git, Github, and RStudio.html",
    "title": "Tutorial: Git, Github, and RStudio",
    "section": "",
    "text": "R has a number of packages that facilitate its use with git. git2r, gitcreds, gh, gert, credentials all work within R to allow the use of git and GitHub. RStudio has good integration with both git and GitHub and if you are working in an RStudio environment it is wise to use the integrated tools.\nThere are a number of steps to be completed before you can use git and GitHub with R and RStudio. You need to make sure you have R and R Studio installed (I will assume this), you must get a GitHub account, then install git on your personal computer, and then let RStudio know about your installation."
  },
  {
    "objectID": "Tutorial-Git, Github, and RStudio.html#sec-installing-git",
    "href": "Tutorial-Git, Github, and RStudio.html#sec-installing-git",
    "title": "Tutorial: Git, Github, and RStudio",
    "section": "Installing git",
    "text": "Installing git\nDifferent operating systems will have different methods for installing git.\n\nWindows\nYou can get. an installer for Windows directly from the git website.\nOnce it has installed open the windows command prompt or within the Termina tab in RStudio then type:\ngit version\nto verify that it has installed.\n\n\nMac\nIt is probably the case that git is pre-installed on your computer. To check you can open the terminal app which is in the Utilities folder in the Applications folder and paste in the following line. Alternatively you can use the terminal tab in the console window in RStudio and paster in the same line.\ngit --version\nIf it is not installed you can install it using Homebrew, follow the instructions here or here. Or you can install Apples own XCode software, although the latter requires downloading a subtantial amount of material (3.21 GB).\n\n\nLinux\nIt is probably the case that git is pre-installed on your computer. However, if it is not use the appropriate package manager to install git for your distro."
  },
  {
    "objectID": "Tutorial-Git, Github, and RStudio.html#sec-let-rstudio-know-about-your-git-installation",
    "href": "Tutorial-Git, Github, and RStudio.html#sec-let-rstudio-know-about-your-git-installation",
    "title": "Tutorial: Git, Github, and RStudio",
    "section": "Let RStudio know about your git installation",
    "text": "Let RStudio know about your git installation\n\nWindows\nYou may have to restart RStudio to let it look in the default place for the git installation. Then you can go to RStudio’s Tool menu and down to Global Options. When you open that select the Git/SVN tab and you should see your window as in Figure 1. If it does not show this then use the Browse button to find the git program in your Program Files. Make sure the “Enable version control interface for RStudio projects” button is ticked.\n\n\n\n\n\n\nFigure 1: Windows RStudio Global Options Version Control Dialog Box\n\n\n\nOnce the dialogue box is correct click the Apply button.\n\n\nMac\nIn RStudio Terminal type or copy and paste\nwhich git\nIt should produce something like:\n/usr/bin/git\nor\n/usr/local/bin/git\nGo to RStudio’s Tool menu and down to Global Options. When you open that select the Git/SVN tab and you should see the dialogue box as in ?@fig-MacRStudioGit. If it does not show this then use the Browse button to find the git program. As these are hidden system files, the UNIX side of MacOS, you may need to access them using the Command+Shift+G key combination.\nMake sure the “Enable version control interface for RStudio projects” button is ticked.\n\n\n\nMac RStudio Global Options Version Control Dialog Box\n\n\nOnce the dialogue box is correct click the Apply button.\n\n\nLinux\nTo be added."
  },
  {
    "objectID": "Tutorial-Git, Github, and RStudio.html#using-git-within-rstudio",
    "href": "Tutorial-Git, Github, and RStudio.html#using-git-within-rstudio",
    "title": "Tutorial: Git, Github, and RStudio",
    "section": "Using git within RStudio",
    "text": "Using git within RStudio\nRStudio has good integration with git and for the most part you should be able to do most things while using the RStudio interface. However, the RStudio interface does not implement all of the functionality that git has; if more functionality is required it is always possible to use the Terminal within RStudio to give git command line commands to achieve what is desired."
  },
  {
    "objectID": "education.html",
    "href": "education.html",
    "title": "Education  ",
    "section": "",
    "text": "The QAA Subject Benchmark Statement for Psychology emphasises the importance of our students developing ‘psychological literacy’ (QAA, 2019). According to the QAA Statement, psychological literacy includes an awareness of current debates and controversies in the discipline, appreciation of ‘rigorous empirical methodology’, critical analysis, and understanding of the relationships between theory and evidence. Given the accelerated discussions within our field about the standards of evidence, the reliability of theoretically consequential findings, and the move towards more Open Science practices that are motivated by these discussions, it is clear that in the present day psychological literacy should include knowledge about Open Science. It is important therefore that students on our undergraduate and postgraduate degree programmes are afforded opportunities to learn about and enact Open Science principles as part of their psychology training. \nThere are already several points in our degree programmes in which the context and/or the principles of Open Science feature as part of students’ education opportunities. These are described below for your awareness of what students on different programmes will be exposed to through their pathways. There are also further steps proposed in these guidelines to increase and enhance the Open Science content of our education delivery. Resources for including Open Science practices in student research projects is detailed elsewhere in these guidelines. Additional resources which have been designed for educational purposes can be found here. \n\n\n\n\nLevel 2 Core Psychology – the ‘replication crisis’ and open science measures in response are covered over three lecture hours as part of Conceptual Issues (typically part of assessment in exam questions) \nLevel 3 thesis – some supervisors encourage thesis students to pre-register projects and/or run replication studies \n\n\n\nCore Psychology – the ‘replication crisis’ and open science measures in response are covered over three lecture hours as part of Conceptual Issues (typically part of assessment in exam questions) \nThesis module– some supervisors encourage thesis students to pre-register projects and/or run replication studies \n\n\n\nResearch Skills – The principles, context and practices of Open Science are thoroughly covered throughout this module (100% assessment – pre-registration assignment) \n\n\n\n\n\n\nLevel 2 Psychological Methods – encourage pre-registration and/or replication studies for Level 2 group research projects \nLevel 3 thesis – encourage pre-registration and/or (conceptual) replication studies and/or meta-analyses for thesis projects; thesis marking criteria to include considerations of how/whether thesis reports demonstrate open science principles in design and reporting of thesis (e.g., transparency of evidence, steps taken to avoid HARKing, actions taken to guard against QRPs). \n\n\n\nMethods, Design, and Analysis in Psychology – encourage pre-registration and/or replication studies for tutorial group projects \nThesis module – encourage pre-registration and/or (conceptual) replication studies and/or meta-analyses for thesis projects; thesis marking criteria to include considerations of how/whether thesis reports demonstrate open science principles in design and reporting of thesis (e.g., transparency of evidence, steps taken to avoid HARKing, actions taken to guard against QRPs) \n\n\n\nDoctoral supervisors increasingly support students in embedding open science practices into their workflows. This includes pre-registering studies where appropriate, obtaining participant consent to share anonymised data, and making available research data, analytic code, research protocols, and other materials via open repositories. Students are advised to consult their supervisors and keep in mind that sharing data and materials may be required by examiners. With Queen’s endorsement of the thesis with publication model, creating a central project page (e.g., on the Open Science Framework) offers several advantages. For instance, it allows students to organise pre-registrations, data, and code from all PhD studies into components or sub-folders within a single project, and share one unified link in their thesis (See the Open Science Framework project FAQ for more details). Importantly, these practices are not limited to users of R or other programming languages.\n\n\n\nMaking project data openly available through a data repository (e.g., OSF). \nPre-registration of research protocols for projects (e.g., OSF, AsPredicted). \nShift to teaching analysis using openly accessible and reproducible data analysis software packages (R with R Markdown, Python with Jupyter, Quarto etc)."
  },
  {
    "objectID": "education.html#where-is-there-open-science-education-in-current-programmes",
    "href": "education.html#where-is-there-open-science-education-in-current-programmes",
    "title": "Education  ",
    "section": "",
    "text": "Level 2 Core Psychology – the ‘replication crisis’ and open science measures in response are covered over three lecture hours as part of Conceptual Issues (typically part of assessment in exam questions) \nLevel 3 thesis – some supervisors encourage thesis students to pre-register projects and/or run replication studies \n\n\n\nCore Psychology – the ‘replication crisis’ and open science measures in response are covered over three lecture hours as part of Conceptual Issues (typically part of assessment in exam questions) \nThesis module– some supervisors encourage thesis students to pre-register projects and/or run replication studies \n\n\n\nResearch Skills – The principles, context and practices of Open Science are thoroughly covered throughout this module (100% assessment – pre-registration assignment)"
  },
  {
    "objectID": "education.html#where-could-open-science-education-be-expanded-reinforced-in-current-programmes",
    "href": "education.html#where-could-open-science-education-be-expanded-reinforced-in-current-programmes",
    "title": "Education  ",
    "section": "",
    "text": "Level 2 Psychological Methods – encourage pre-registration and/or replication studies for Level 2 group research projects \nLevel 3 thesis – encourage pre-registration and/or (conceptual) replication studies and/or meta-analyses for thesis projects; thesis marking criteria to include considerations of how/whether thesis reports demonstrate open science principles in design and reporting of thesis (e.g., transparency of evidence, steps taken to avoid HARKing, actions taken to guard against QRPs). \n\n\n\nMethods, Design, and Analysis in Psychology – encourage pre-registration and/or replication studies for tutorial group projects \nThesis module – encourage pre-registration and/or (conceptual) replication studies and/or meta-analyses for thesis projects; thesis marking criteria to include considerations of how/whether thesis reports demonstrate open science principles in design and reporting of thesis (e.g., transparency of evidence, steps taken to avoid HARKing, actions taken to guard against QRPs) \n\n\n\nDoctoral supervisors increasingly support students in embedding open science practices into their workflows. This includes pre-registering studies where appropriate, obtaining participant consent to share anonymised data, and making available research data, analytic code, research protocols, and other materials via open repositories. Students are advised to consult their supervisors and keep in mind that sharing data and materials may be required by examiners. With Queen’s endorsement of the thesis with publication model, creating a central project page (e.g., on the Open Science Framework) offers several advantages. For instance, it allows students to organise pre-registrations, data, and code from all PhD studies into components or sub-folders within a single project, and share one unified link in their thesis (See the Open Science Framework project FAQ for more details). Importantly, these practices are not limited to users of R or other programming languages.\n\n\n\nMaking project data openly available through a data repository (e.g., OSF). \nPre-registration of research protocols for projects (e.g., OSF, AsPredicted). \nShift to teaching analysis using openly accessible and reproducible data analysis software packages (R with R Markdown, Python with Jupyter, Quarto etc)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Queen’s University Belfast, School of Psychology, Open Science Workgroup",
    "section": "",
    "text": "Queen’s University Belfast, School of Psychology, Open Science Workgroup\nJoost Dessing, Lisa Graham-Wisener, Matthew Rodger, Gillian Shorter, Gary McKeown, Martin Robinson, Bethan Iley, Agnieszka Graham, Elida Cena.\nWelcome to the School of Psychology Open Science Guidelines, created for your benefit by the Open Science Workgroup of the School of Psychology at Queen’s University Belfast. You can navigate the content by using the menu bar at the top and through links contained within the text. This is a live and working document that will be updated as more materials become available and as new Open Science Practices become available.\n\n\n\n\n\nIf you are new to Open Science as useful glossary of terms is provided via the Open Science Dictionary.\nPast members:\nPaul Toner, Tanja Gerlach, Thomas Schultze-Gerlach."
  },
  {
    "objectID": "open_materials.html",
    "href": "open_materials.html",
    "title": "Open Materials ",
    "section": "",
    "text": "We encourage staff to share their materials where appropriate. \n\n\nOpen Materials refer to the public sharing of materials used in our research. This can refer to any materials used in the study: information (e.g., questionnaires), code, [description of] experimental set-ups. Just like Open Data, the sharing of materials greatly promotes reproducibility. Moreover, Open Materials increases efficiency in science, since it allows researchers to benefit from efforts of others. Sharing of code underlying data analyses together with Open Data helps other to verify the validity of any inferences/conclusions; this can include detection of issues with computer code. FAIR principles are again an important guidance here: Findability, Accessibility, Interoperability and Reuse.  \n\n\n\n\nMaximizing transparency to promote reproducibility and detection of problems \nMaximizing usefulness of materials contributing to science and its progress \n\n\n\n\nYou can share any materials you used in the research process as long as you have permission for this of course. Please pay particular attention to ethical permissions, copyright, and the wishes of the creators of the materials ; also consider fair use of any materials. Deposited information may include: \n\nBlank information sheets \nBlank consent forms \nStimuli or other materials sent to participants \nComputer code used to generate any materials or stimuli for the study \nAnalysis input and output \nBlank questionnaires or interview schedules \nData Management Plans \nFull protocol information (e.g., SPIRIT protocol items for trials) \nAny other curated information which illustrates how you reached conclusions (e.g., decisions made on papers for a systematic review). \n\n\n\n\n\nDecide on your licence \n\nResearchers should apply an open licence to each item to reduce issues around ambiguity and what can and cannot be done with deposited materials. This licence is most often a specified Creative Commons licence (click on the link to identify the right licence for you). Please note without a licence it can be used without credit or acknowledgement of the source. \n\nObserve the guidelines on deposit of research materials \n\nThe guidelines on research conduct at Queen’s University Belfast are available at Standard Operating Procedures. If in doubt, seek advice before deposit.  \nSetting Up, Maintaining and Archiving Research Files and  \nData Management, Collection, Validation and Storage  \n\nMake sure the materials are suitable for deposit using FAIR principles \n\nFAIR principles should be applied. Materials should be \nFindable – data should have a Digital Object Identifier (DOI) which allows it to be easily found using search tools. \nAccessible – materials should be accessible to others and deposited on a credible repository. \nInteroperable – materials formats should be adaptable to multiple platforms for future use.  \nReusable – materials should be clearly labelled with an accompanying licence (often CC BY 4.0, but for more information see the creative commons licence link above).  \nFAIR principles should motivate us to organize the materials logically and accompany it by documentation. As you prepare your materials you may consider that they will be publicly available and deposit as you go along.  \n\nLink manuscript with your materials \n\nUse the DOI in your manuscript as you submit to a journal to illustrate where your open materials are sourced. You may be able to describe the materials in the section in the manuscript or it may be useful to link to an overarching page (e.g., on the Open Science Framework), which represents the project where space is limited. \n\nMake some decisions about your materials and encourage others to engage with your work \n\nYou can put an embargo on the date at which materials can be accessed such as 12 months from deposit to allow you to publish the papers you wish from the research. You may also wish to put out a statement regarding re-use of the materials: \nMaterials may be used without express permission from the authors if the following conditions are met.  \nPlease cite the source of the data as: \nJones, A.B. (2022). Name of OSF page [Open Science Materials]. Queen’s University Belfast. https://doi.org/01234.5678910  \nJones, A.B. (2022). First paper describing the results of the research project. Journal of Open Science Research. 1(2), 101-102. https://doi.org/10.01234.5678910 \nPlease contact the lead author Professor Jones a.jones@qub.ac.uk with any publications arising from the materials used and share best practice. \n\n\n\nQUB encourages researchers to share their research data through Pure (https://pure.qub.ac.uk/en/datasets/) but for open materials it may make more sense to use the repositories below.  \nResearch Box  \n\nMirroring AsPredicted.org\nData and materials archive \n\nOpen Science Framework \n\nPlatform dedicated to Open Science.\nMultiple server locations\nCan host the information in one place. \n\nZenodo \n\nServers based at CERN \n\nGithub \n\nA repository widely used for software development version control, forking. \n\n\n\n\nShould all materials be shared? \nNo. If materials are already publicly accessible, there is no need to share this again. Moreover, some materials may not be published because of copyright or intellectual property restrictions, or future potential thereof. Ethical or safety concerns may also apply, particularly in the development stage (e.g., for treatments). \nIs it extra work? \nYes. Many of the repositories require creating an account. Moreover, while uploading materials nowadays typically is a drag-and-drop exercise, FAIR principles should motivate us to organize these logically and accompany it by descriptors."
  },
  {
    "objectID": "open_materials.html#what-are-open-materials",
    "href": "open_materials.html#what-are-open-materials",
    "title": "Open Materials ",
    "section": "",
    "text": "Open Materials refer to the public sharing of materials used in our research. This can refer to any materials used in the study: information (e.g., questionnaires), code, [description of] experimental set-ups. Just like Open Data, the sharing of materials greatly promotes reproducibility. Moreover, Open Materials increases efficiency in science, since it allows researchers to benefit from efforts of others. Sharing of code underlying data analyses together with Open Data helps other to verify the validity of any inferences/conclusions; this can include detection of issues with computer code. FAIR principles are again an important guidance here: Findability, Accessibility, Interoperability and Reuse."
  },
  {
    "objectID": "open_materials.html#benefits",
    "href": "open_materials.html#benefits",
    "title": "Open Materials ",
    "section": "",
    "text": "Maximizing transparency to promote reproducibility and detection of problems \nMaximizing usefulness of materials contributing to science and its progress"
  },
  {
    "objectID": "open_materials.html#what-materials-should-be-shared",
    "href": "open_materials.html#what-materials-should-be-shared",
    "title": "Open Materials ",
    "section": "",
    "text": "You can share any materials you used in the research process as long as you have permission for this of course. Please pay particular attention to ethical permissions, copyright, and the wishes of the creators of the materials ; also consider fair use of any materials. Deposited information may include: \n\nBlank information sheets \nBlank consent forms \nStimuli or other materials sent to participants \nComputer code used to generate any materials or stimuli for the study \nAnalysis input and output \nBlank questionnaires or interview schedules \nData Management Plans \nFull protocol information (e.g., SPIRIT protocol items for trials) \nAny other curated information which illustrates how you reached conclusions (e.g., decisions made on papers for a systematic review)."
  },
  {
    "objectID": "open_materials.html#how-to-deposit-and-curate-your-materials",
    "href": "open_materials.html#how-to-deposit-and-curate-your-materials",
    "title": "Open Materials ",
    "section": "",
    "text": "Decide on your licence \n\nResearchers should apply an open licence to each item to reduce issues around ambiguity and what can and cannot be done with deposited materials. This licence is most often a specified Creative Commons licence (click on the link to identify the right licence for you). Please note without a licence it can be used without credit or acknowledgement of the source. \n\nObserve the guidelines on deposit of research materials \n\nThe guidelines on research conduct at Queen’s University Belfast are available at Standard Operating Procedures. If in doubt, seek advice before deposit.  \nSetting Up, Maintaining and Archiving Research Files and  \nData Management, Collection, Validation and Storage  \n\nMake sure the materials are suitable for deposit using FAIR principles \n\nFAIR principles should be applied. Materials should be \nFindable – data should have a Digital Object Identifier (DOI) which allows it to be easily found using search tools. \nAccessible – materials should be accessible to others and deposited on a credible repository. \nInteroperable – materials formats should be adaptable to multiple platforms for future use.  \nReusable – materials should be clearly labelled with an accompanying licence (often CC BY 4.0, but for more information see the creative commons licence link above).  \nFAIR principles should motivate us to organize the materials logically and accompany it by documentation. As you prepare your materials you may consider that they will be publicly available and deposit as you go along.  \n\nLink manuscript with your materials \n\nUse the DOI in your manuscript as you submit to a journal to illustrate where your open materials are sourced. You may be able to describe the materials in the section in the manuscript or it may be useful to link to an overarching page (e.g., on the Open Science Framework), which represents the project where space is limited. \n\nMake some decisions about your materials and encourage others to engage with your work \n\nYou can put an embargo on the date at which materials can be accessed such as 12 months from deposit to allow you to publish the papers you wish from the research. You may also wish to put out a statement regarding re-use of the materials: \nMaterials may be used without express permission from the authors if the following conditions are met.  \nPlease cite the source of the data as: \nJones, A.B. (2022). Name of OSF page [Open Science Materials]. Queen’s University Belfast. https://doi.org/01234.5678910  \nJones, A.B. (2022). First paper describing the results of the research project. Journal of Open Science Research. 1(2), 101-102. https://doi.org/10.01234.5678910 \nPlease contact the lead author Professor Jones a.jones@qub.ac.uk with any publications arising from the materials used and share best practice."
  },
  {
    "objectID": "open_materials.html#where-to-share-materials",
    "href": "open_materials.html#where-to-share-materials",
    "title": "Open Materials ",
    "section": "",
    "text": "QUB encourages researchers to share their research data through Pure (https://pure.qub.ac.uk/en/datasets/) but for open materials it may make more sense to use the repositories below.  \nResearch Box  \n\nMirroring AsPredicted.org\nData and materials archive \n\nOpen Science Framework \n\nPlatform dedicated to Open Science.\nMultiple server locations\nCan host the information in one place. \n\nZenodo \n\nServers based at CERN \n\nGithub \n\nA repository widely used for software development version control, forking."
  },
  {
    "objectID": "open_materials.html#common-questions",
    "href": "open_materials.html#common-questions",
    "title": "Open Materials ",
    "section": "",
    "text": "Should all materials be shared? \nNo. If materials are already publicly accessible, there is no need to share this again. Moreover, some materials may not be published because of copyright or intellectual property restrictions, or future potential thereof. Ethical or safety concerns may also apply, particularly in the development stage (e.g., for treatments). \nIs it extra work? \nYes. Many of the repositories require creating an account. Moreover, while uploading materials nowadays typically is a drag-and-drop exercise, FAIR principles should motivate us to organize these logically and accompany it by descriptors."
  },
  {
    "objectID": "Tutorial_2-GitWorkflows.html",
    "href": "Tutorial_2-GitWorkflows.html",
    "title": "Tutorial 2-Git Workflows",
    "section": "",
    "text": "This is the workflow that should only be used for solo experimentation phases it is frowned upon, and Jenny Bryan recommends going straight to collaborative workflows as it is in that setting that the most benefit is seen from the extra learning required in the use of Git and Github. However, following this talk by Colin Gillespie—Getting the Most Out of Git - posit::conf(2023)—I will recommend this basic workflow in a small number of circumstances and it offers a nice stepping stone to more complex workflows.\nFollowing Colin Gillespie’s advice the situations in which the basic workflow or “standard process” is suitable is when you have code or documents that do not have importance for many people other than yourself, for example, when you have to produce one off code for slides, or when you are just at the start of a project.\nOne of the most important things that Git brings to version control are the branches and this standard process or workflow ignores branches—we will cover them soon. For the moment, we can largely ignore them except to be aware that all git repositories or repos have at least one branch—or perhaps to take the analogy to its conclusion the central trunk, nowadays, that is known as the main branch. This is the branch that keeps track of all the changes that you make and represents the current canonical version of your code or document, and it contains a historical list of all the changes that have happened to your code and documents over time.\nIn the most basic workflow you just keep this branch and commit and push to it."
  },
  {
    "objectID": "Tutorial_2-GitWorkflows.html#git-workflows",
    "href": "Tutorial_2-GitWorkflows.html#git-workflows",
    "title": "Tutorial 2-Git Workflows",
    "section": "",
    "text": "This is the workflow that should only be used for solo experimentation phases it is frowned upon, and Jenny Bryan recommends going straight to collaborative workflows as it is in that setting that the most benefit is seen from the extra learning required in the use of Git and Github. However, following this talk by Colin Gillespie—Getting the Most Out of Git - posit::conf(2023)—I will recommend this basic workflow in a small number of circumstances and it offers a nice stepping stone to more complex workflows.\nFollowing Colin Gillespie’s advice the situations in which the basic workflow or “standard process” is suitable is when you have code or documents that do not have importance for many people other than yourself, for example, when you have to produce one off code for slides, or when you are just at the start of a project.\nOne of the most important things that Git brings to version control are the branches and this standard process or workflow ignores branches—we will cover them soon. For the moment, we can largely ignore them except to be aware that all git repositories or repos have at least one branch—or perhaps to take the analogy to its conclusion the central trunk, nowadays, that is known as the main branch. This is the branch that keeps track of all the changes that you make and represents the current canonical version of your code or document, and it contains a historical list of all the changes that have happened to your code and documents over time.\nIn the most basic workflow you just keep this branch and commit and push to it."
  },
  {
    "objectID": "github.html",
    "href": "github.html",
    "title": "Git and GitHub",
    "section": "",
    "text": "Version control is any of a variety of systems that have been developed to keep track of source code as it is being written. In some ways it can be though of as similar to a track changes system in a word processing programme, but it is much more comprehensive. The goal of version control is to keep track of every change that has been made to a document or set of documents in a way that allows changes to be recorded, documented, and rolled back if necessary. As reproducible documents are written as code a version control system is a good way to keep track of the associated files containing the relevant documents and data. It also enables ways to make them available for public scrutiny.\nA number of systems have been created to do version control for software and documents. One of the earliest modern systems was CSV which stood for Concurrent Versions System, this was the most popular system until Subversion (SVN) arrived, which then dominated until git arrived. Git has dominated ever since. There have also been more commerical systems that have been popular in enterprise setting such as BitKeeper and Perforce."
  },
  {
    "objectID": "github.html#what-is-version-control",
    "href": "github.html#what-is-version-control",
    "title": "Git and GitHub",
    "section": "",
    "text": "Version control is any of a variety of systems that have been developed to keep track of source code as it is being written. In some ways it can be though of as similar to a track changes system in a word processing programme, but it is much more comprehensive. The goal of version control is to keep track of every change that has been made to a document or set of documents in a way that allows changes to be recorded, documented, and rolled back if necessary. As reproducible documents are written as code a version control system is a good way to keep track of the associated files containing the relevant documents and data. It also enables ways to make them available for public scrutiny.\nA number of systems have been created to do version control for software and documents. One of the earliest modern systems was CSV which stood for Concurrent Versions System, this was the most popular system until Subversion (SVN) arrived, which then dominated until git arrived. Git has dominated ever since. There have also been more commerical systems that have been popular in enterprise setting such as BitKeeper and Perforce."
  },
  {
    "objectID": "github.html#what-is",
    "href": "github.html#what-is",
    "title": "Git and GitHub",
    "section": "What is ?",
    "text": "What is ?\nGit is a version control system developed in 2005 by Linus Torvalds, the person who originally developed the Linux operating system. It was developed for work on the Linux opertaing system’s kernal. It is designed to be a distributed system allowing thousands of coders to hold code on different computers and allow them to be merged together to form a coherent code base for a product or system. There can be many parallel branches of the code. The fact that it was designed for thousands of coders to use at once and yet maintain a coherent and functioning codebase makes it a good system for scientific collaboration. It works on all of the major operating systems and there should be minimal problems there. As it has origins in Linux development it probably works more easily in UNIX-style evironments like Linux and MacOS, but, given the popularity of Windows, attention has paid to making it work seamlessly with Windows products. This does lead to the issue of instructions being a little differetn depending on the computer you are using. Git is free and open source software.\nGit operates by having a main repository that contains the code or documents, this typically sits on a main server. Users then clone copies of the full repository to their personal computers. Each of these copies can serve as a abackup of the whole system. This main repository view is a centralized workflow and is one of the most common styles of development, but there are other more complicated workflows. Users can then make changes, commit them to their local repository and then push them to the main repository. Git allows multiple workers to work on software and ensures that they do not overwrite one another’s work."
  },
  {
    "objectID": "github.html#what-is-github",
    "href": "github.html#what-is-github",
    "title": "Git and GitHub",
    "section": " What is GitHub?",
    "text": "What is GitHub?\nGit and GitHub are different entities and it is important that they are not confused although they are often used in parallel. GitHub is a cloud-based platform that serves as a host for git repositories, it also adds some additional features such as wikis, access control, bug tracking and website creation—this website is hosted using this feature. In most use cases for Open Science GitHub serves as the main repository with individual personal computers serving as local repositories. Figure 1 demonstrates the typical workflow for most Open Science GitHub projects.\n\n\n\n\n\n\nFigure 1: A Basic GitHub Workflow\n\n\n\nIn January 2023 GitHub reported that it had over 100 million Developers using its platform and as of June 2022, GitHub reported that there are more than 200 million active repositories. GitHub is a commercail entity and has been owned by Microsoft since 2018 who acquried it for $7.5 billion. The commercial nature of GitHub has led to some unease over its use in Open Science and for Open Source software, however, the ease of use it offers and the familiarity means that it remains a compelling solution for users.\nTo learn how to use git and GitHub With RStudio see the tutorial."
  },
  {
    "objectID": "preregistration.html",
    "href": "preregistration.html",
    "title": "Preregistration for Quantitative Methods",
    "section": "",
    "text": "We encourage staff to preregister their research as standard.\n\n\nPreregistration involves publishing your plans in a protocol for research before you conduct the research. A preregistration can benefit research quality if it is version-controlled, time-stamped, and deposited in a publicly accessible repository. This practice ensures that any change to the research plans or protocol can be traced, which disincentivizes presenting a changed protocol as the original, intended protocol - this is relevant if such changes are data-inspired. The more detailed the preregistered protocol, the more it prevents results being influenced – even inadvertently – by undisclosed flexibility in research practices, which is known to affect replicability. Most pre-registered information should include the following:\n\nA statement of the hypotheses/research questions being assessed\n\n\n\nA clear methodology that can be reproduced by other researchers\n\n\n\nThe variables that will be measured and theoretical lens by which these will be viewed\n\n\n\nAn indication of the intended sample size (ideally justified with a power analysis for confirmatory research), how this will be obtained (recruitment) and what criteria will govern inclusion and exclusion of participants and data.\n\n\n\nA detailed description of the intended data analysis that will underlie any inferences drawn\n\n\n\n\n\n\nMore robust and transparent research: increased trustworthiness and confidence in reproducibility and replicability\nClarity on dissociation between confirmatory and exploratory analyses\nClarity on plan for research team – a document to guide all steps from data collection to data analyses\n\n\n\nAvoiding any suggestion that undisclosed flexibility influenced the inferences drawn\nAvailable as article type (Registered Reports), affording publication of confirmatory science irrespective of results (see below)\nResearchers are being criticized for P-hacking (reporting only significant findings) and HARKing (hypothesising after the results are known) within scientific research; through preregistration we can illustrate that we do not engage in these practices\n\n\n\n\nAll types of research can be pre-registered. Preregistration can be used for both confirmatory and exploratory research. Besides quantitative experimental designs, this includes among others observational designs, survey designs, randomized trials, secondary data analyses, qualitative interviews, ethnographies or focus groups, and systematic reviews. The key here is that the preregistration provides transparency about what the research plan was prior to data collection. For some designs such as ethnography or qualitative interviews, minimal information may be known in advance; for others such as randomised controlled trials, much more information will be known and available for preregistration.\n\n\n\nHow and where to register your protocols depends on the purpose and the type of research you are conducting. Several online repositories have been created that are optimized for the practice of preregistration and transparency (e.g., version control, links to data). These are given below.\nThere may be different requirements for each type of research and the Equator Network have provided guidance on what to include in protocols for a selection of different designs. You can also publish the protocol as a peer-reviewed journal article, but this should be considered in addition to the registrations below given the time the peer-review process takes. One way around this may be to deposit the protocol as a pre-print on a server such as PsyArXiv (if your chosen journal facilitates this; see Sherpa Romeo).\n\n\n\nBelow, we list the main repositories to help staff get started with preregistration on these portals.\nhttps://AsPredicted.org\n\nMainly for quantitative research\nAnswer 10 questions about research protocol\nAnswers saved as pdf website\nExample: Valkanidis, Doumas, and Dessing (2020)\nResearchers control the visibility (private or public).\n\nOpen Science Framework | OSF Preregistration\n\nPlatform dedicated to Open Science, so data, materials, and preregistration are all hosted within the same project\n\n\n\nVariety of formats for specific types of research (e.g., quantitative, qualitative, systematic reviews, scoping reviews, secondary data analyses); this includes the AsPredicted format mentioned above\nCan be helpful for student preregistrations (supervisors are encouraged to create a single page for a given academic year cohort e.g., 2022/2023, with folders for each registered project)\nExamples: Reid and Dessing (2016), Schultze, Gerlach and Rittich ( 2017)\n\nClinicalTrials.gov\n\nPreregistration of clinical trials\nIt is an ethical requirement as per the Declaration of Helsinki that every clinical trial, if considered medical, must be registered in a publicly accessible database before recruitment of the first participant. A list of other registration sites are: Primary Registries in the WHO Registry Network or an ICMJE approved registry. Please note that some of these may incur a charge. For trials you should also complete a SPIRIT protocol document for your Trial Master file.\n\nPROSPERO (york.ac.uk)\n\nPreregistration of systematic reviews\n\n\n\nIf you are aiming to publish your systematic review, you may severely limit your publication chances if you do not preregister your review. Good guidance on systematic review conduct can be found on York Centre for Reviews and Dissemination. To minimize work for the team at PROSPERO, only those reviews you intend to publish should be hosted at this site. For reviews in the context of teaching the Open Science Framework is more appropriate, but the preregistration could follow the structure of the PROSPERO registration.\n\nCOMET Initiative\n\nFor core outcome sets or minimum data standards\n\nPlease consider depositing your preregistration on the PURE platform after you have registered it on one of the platforms above. To do so, log into your PURE account, go to research outputs, other contribution, protocol, and select either peer-reviewed (e.g., Prospero) or non-peer-reviewed (e.g., OSF) and link to the DOI. You might also want to highlight this as a protocol in the title of the deposit to minimise confusion if you use the same title for the paper arising from the work.\n\n\n\nThis is a form of preregistration for confirmatory science, where a paper is accepted by journals at the protocol stage, prior to data collection. The protocol goes through the peer review process where the introduction, hypotheses, methods and analysis plan are scrutinized before data is collected. If accepted, the journal commits to publishing the full report irrespective of the results, as long as the preregistered protocol is followed and the conclusions are justified by the data.\nOnce data is collected and analyzed the registered report is updated with the findings and write up and is resubmitted to the same journal for further peer review. You can read more about registered reports here. The site linked also contains a list of journals already offering the registered reports format. Note, however, that this approach may have implications which compete with time demands of external funders or student supervision.\n\n\n\nDoesn’t preregistration stifle exploration and creativity?\nNo. Nothing prevents further exploration of the patterns within a dataset. Preregistration just ensures that such analyses are appropriately identified as exploratory. Plans can also change, and this can be reflected in an updated version of the preregistered protocol prior to research start, or if research has already started, then transparently reported and explained as a deviation from the protocol in the write up.\nIs it extra work?\nYes and no. Yes, preregistration typically involves an in-depth research protocol, the details of which may take more time to iron out. However, since most research within Psychology requires an ethics application, which also involves a research protocol, at least part of the information is already written down even without preregistration. Indeed, QUB’s ethics procedures will soon streamline this process with the particular aim to avoid extra work. Critically, preregistration changes the order in which researchers spend time: putting in more effort before data collection reduces the time needed from data collection to dissemination.\nIf I preregister elsewhere why do I need to add it to my PURE repository?\nAny preregistration on any site/portal implies that you are doing the work; it creates an easily searchable protocol, which individuals who are considering similar work can see to avoid duplication of effort (e.g., in reviews), or to guide replication efforts (e.g., replication studies).\nIt is useful to deposit your published preregistration on PURE as it can link to the final publication when it has been published; this demonstrates your (and your co-authors’) commitment to open science, and institutional commitment to open science which grows our research reputation."
  },
  {
    "objectID": "preregistration.html#what-is-preregistration",
    "href": "preregistration.html#what-is-preregistration",
    "title": "Preregistration for Quantitative Methods",
    "section": "",
    "text": "Preregistration involves publishing your plans in a protocol for research before you conduct the research. A preregistration can benefit research quality if it is version-controlled, time-stamped, and deposited in a publicly accessible repository. This practice ensures that any change to the research plans or protocol can be traced, which disincentivizes presenting a changed protocol as the original, intended protocol - this is relevant if such changes are data-inspired. The more detailed the preregistered protocol, the more it prevents results being influenced – even inadvertently – by undisclosed flexibility in research practices, which is known to affect replicability. Most pre-registered information should include the following:\n\nA statement of the hypotheses/research questions being assessed\n\n\n\nA clear methodology that can be reproduced by other researchers\n\n\n\nThe variables that will be measured and theoretical lens by which these will be viewed\n\n\n\nAn indication of the intended sample size (ideally justified with a power analysis for confirmatory research), how this will be obtained (recruitment) and what criteria will govern inclusion and exclusion of participants and data.\n\n\n\nA detailed description of the intended data analysis that will underlie any inferences drawn"
  },
  {
    "objectID": "preregistration.html#what-are-the-benefits-of-preregistration",
    "href": "preregistration.html#what-are-the-benefits-of-preregistration",
    "title": "Preregistration for Quantitative Methods",
    "section": "",
    "text": "More robust and transparent research: increased trustworthiness and confidence in reproducibility and replicability\nClarity on dissociation between confirmatory and exploratory analyses\nClarity on plan for research team – a document to guide all steps from data collection to data analyses\n\n\n\nAvoiding any suggestion that undisclosed flexibility influenced the inferences drawn\nAvailable as article type (Registered Reports), affording publication of confirmatory science irrespective of results (see below)\nResearchers are being criticized for P-hacking (reporting only significant findings) and HARKing (hypothesising after the results are known) within scientific research; through preregistration we can illustrate that we do not engage in these practices"
  },
  {
    "objectID": "preregistration.html#what-types-of-research-could-be-preregistered",
    "href": "preregistration.html#what-types-of-research-could-be-preregistered",
    "title": "Preregistration for Quantitative Methods",
    "section": "",
    "text": "All types of research can be pre-registered. Preregistration can be used for both confirmatory and exploratory research. Besides quantitative experimental designs, this includes among others observational designs, survey designs, randomized trials, secondary data analyses, qualitative interviews, ethnographies or focus groups, and systematic reviews. The key here is that the preregistration provides transparency about what the research plan was prior to data collection. For some designs such as ethnography or qualitative interviews, minimal information may be known in advance; for others such as randomised controlled trials, much more information will be known and available for preregistration."
  },
  {
    "objectID": "preregistration.html#how-do-i-preregister-my-plansprotocols-for-research",
    "href": "preregistration.html#how-do-i-preregister-my-plansprotocols-for-research",
    "title": "Preregistration for Quantitative Methods",
    "section": "",
    "text": "How and where to register your protocols depends on the purpose and the type of research you are conducting. Several online repositories have been created that are optimized for the practice of preregistration and transparency (e.g., version control, links to data). These are given below.\nThere may be different requirements for each type of research and the Equator Network have provided guidance on what to include in protocols for a selection of different designs. You can also publish the protocol as a peer-reviewed journal article, but this should be considered in addition to the registrations below given the time the peer-review process takes. One way around this may be to deposit the protocol as a pre-print on a server such as PsyArXiv (if your chosen journal facilitates this; see Sherpa Romeo)."
  },
  {
    "objectID": "preregistration.html#main-pre-registration-repositories",
    "href": "preregistration.html#main-pre-registration-repositories",
    "title": "Preregistration for Quantitative Methods",
    "section": "",
    "text": "Below, we list the main repositories to help staff get started with preregistration on these portals.\nhttps://AsPredicted.org\n\nMainly for quantitative research\nAnswer 10 questions about research protocol\nAnswers saved as pdf website\nExample: Valkanidis, Doumas, and Dessing (2020)\nResearchers control the visibility (private or public).\n\nOpen Science Framework | OSF Preregistration\n\nPlatform dedicated to Open Science, so data, materials, and preregistration are all hosted within the same project\n\n\n\nVariety of formats for specific types of research (e.g., quantitative, qualitative, systematic reviews, scoping reviews, secondary data analyses); this includes the AsPredicted format mentioned above\nCan be helpful for student preregistrations (supervisors are encouraged to create a single page for a given academic year cohort e.g., 2022/2023, with folders for each registered project)\nExamples: Reid and Dessing (2016), Schultze, Gerlach and Rittich ( 2017)\n\nClinicalTrials.gov\n\nPreregistration of clinical trials\nIt is an ethical requirement as per the Declaration of Helsinki that every clinical trial, if considered medical, must be registered in a publicly accessible database before recruitment of the first participant. A list of other registration sites are: Primary Registries in the WHO Registry Network or an ICMJE approved registry. Please note that some of these may incur a charge. For trials you should also complete a SPIRIT protocol document for your Trial Master file.\n\nPROSPERO (york.ac.uk)\n\nPreregistration of systematic reviews\n\n\n\nIf you are aiming to publish your systematic review, you may severely limit your publication chances if you do not preregister your review. Good guidance on systematic review conduct can be found on York Centre for Reviews and Dissemination. To minimize work for the team at PROSPERO, only those reviews you intend to publish should be hosted at this site. For reviews in the context of teaching the Open Science Framework is more appropriate, but the preregistration could follow the structure of the PROSPERO registration.\n\nCOMET Initiative\n\nFor core outcome sets or minimum data standards\n\nPlease consider depositing your preregistration on the PURE platform after you have registered it on one of the platforms above. To do so, log into your PURE account, go to research outputs, other contribution, protocol, and select either peer-reviewed (e.g., Prospero) or non-peer-reviewed (e.g., OSF) and link to the DOI. You might also want to highlight this as a protocol in the title of the deposit to minimise confusion if you use the same title for the paper arising from the work."
  },
  {
    "objectID": "preregistration.html#registered-reports",
    "href": "preregistration.html#registered-reports",
    "title": "Preregistration for Quantitative Methods",
    "section": "",
    "text": "This is a form of preregistration for confirmatory science, where a paper is accepted by journals at the protocol stage, prior to data collection. The protocol goes through the peer review process where the introduction, hypotheses, methods and analysis plan are scrutinized before data is collected. If accepted, the journal commits to publishing the full report irrespective of the results, as long as the preregistered protocol is followed and the conclusions are justified by the data.\nOnce data is collected and analyzed the registered report is updated with the findings and write up and is resubmitted to the same journal for further peer review. You can read more about registered reports here. The site linked also contains a list of journals already offering the registered reports format. Note, however, that this approach may have implications which compete with time demands of external funders or student supervision."
  },
  {
    "objectID": "preregistration.html#common-questions",
    "href": "preregistration.html#common-questions",
    "title": "Preregistration for Quantitative Methods",
    "section": "",
    "text": "Doesn’t preregistration stifle exploration and creativity?\nNo. Nothing prevents further exploration of the patterns within a dataset. Preregistration just ensures that such analyses are appropriately identified as exploratory. Plans can also change, and this can be reflected in an updated version of the preregistered protocol prior to research start, or if research has already started, then transparently reported and explained as a deviation from the protocol in the write up.\nIs it extra work?\nYes and no. Yes, preregistration typically involves an in-depth research protocol, the details of which may take more time to iron out. However, since most research within Psychology requires an ethics application, which also involves a research protocol, at least part of the information is already written down even without preregistration. Indeed, QUB’s ethics procedures will soon streamline this process with the particular aim to avoid extra work. Critically, preregistration changes the order in which researchers spend time: putting in more effort before data collection reduces the time needed from data collection to dissemination.\nIf I preregister elsewhere why do I need to add it to my PURE repository?\nAny preregistration on any site/portal implies that you are doing the work; it creates an easily searchable protocol, which individuals who are considering similar work can see to avoid duplication of effort (e.g., in reviews), or to guide replication efforts (e.g., replication studies).\nIt is useful to deposit your published preregistration on PURE as it can link to the final publication when it has been published; this demonstrates your (and your co-authors’) commitment to open science, and institutional commitment to open science which grows our research reputation."
  },
  {
    "objectID": "Tutorial_1-Git,Github,andRStudio.html",
    "href": "Tutorial_1-Git,Github,andRStudio.html",
    "title": "Tutorial 1: Git, Github, and RStudio",
    "section": "",
    "text": "R has a number of packages that facilitate its use with Git. git2r, gitcreds, gh, gert, credentials all work within R to allow the use of Git and GitHub. RStudio has good integration with both Git and GitHub and if you are working in an RStudio environment it is wise to use the integrated tools.\nThere are a number of steps to be completed before you can use Git and GitHub with R and RStudio. You need to make sure you have R and R Studio installed (I will assume this), you must get a GitHub account, then install Git on your personal computer, and then let RStudio know about your installation.\nThere is also a much more comprehensive guide to using Git and R at Happy Git and GitHub for the useR by Jennifer Bryan. See that for more detailed resources."
  },
  {
    "objectID": "Tutorial_1-Git,Github,andRStudio.html#sec-installing-git",
    "href": "Tutorial_1-Git,Github,andRStudio.html#sec-installing-git",
    "title": "Tutorial 1: Git, Github, and RStudio",
    "section": "Installing Git",
    "text": "Installing Git\nDifferent operating systems will have different methods for installing Git.\n\nWindows\nYou can get an installer for Windows directly from the Git website.\nHowever, a better option is to install “Git for Windows” which installs Git and some other tools, in particular a bash emulator. This makes the Windows version work in the same way as the Unix versions (Linux, MacOS), as the Git comes from the Linux world it is better to stay within the Linux/Unix way of doing things. It also means that learning transfers across platforms.\nAccept the defaults except in the “Adjusting your PATH environment” question, select “Git from the command line and also from 3rd-party software”\nOnce it has installed open the windows command prompt or within the Terminal tab in RStudio then type:\nGit version\nto verify that it has installed.\n\n\nMac\nIt is probably the case that Git is pre-installed on your computer. To check you can open the terminal app which is in the Utilities folder in the Applications folder and paste in the following line. Alternatively you can use the terminal tab in the console window in RStudio and paster in the same line.\ngit --version\nIf it is not installed you can install it using Homebrew, follow the instructions here or here. Or you can install Apples own XCode software, although the latter requires downloading a subtantial amount of material (3.21 GB).\n\n\nLinux\nIt is probably the case that Git is pre-installed on your computer. However, if it is not use the appropriate package manager to install Git for your distro."
  },
  {
    "objectID": "Tutorial_1-Git,Github,andRStudio.html#sec-let-rstudio-know-about-your-git-installation",
    "href": "Tutorial_1-Git,Github,andRStudio.html#sec-let-rstudio-know-about-your-git-installation",
    "title": "Tutorial 1: Git, Github, and RStudio",
    "section": "Let RStudio know about your Git installation",
    "text": "Let RStudio know about your Git installation\n\nWindows\nYou may have to restart RStudio to let it look in the default place for the Git installation. Then you can go to RStudio’s Tool menu and down to Global Options. When you open that select the Git/SVN tab and you should see your window as in Figure 1. If it does not show this then use the Browse button to find the Git program in your Program Files. Make sure the “Enable version control interface for RStudio projects” button is ticked.\n\n\n\n\n\n\nFigure 1: Windows RStudio Global Options Version Control Dialog Box\n\n\n\nOnce the dialogue box is correct click the Apply button.\n\n\nMac\nIn RStudio Terminal type or copy and paste\nwhich git\nIt should produce something like:\n/usr/bin/git\nor\n/usr/local/bin/git\nGo to RStudio’s Tool menu and down to Global Options. When you open that select the Git/SVN tab and you should see the dialogue box as in Figure 2. If it does not show this then use the Browse button to find the Git program. As these are hidden system files, the UNIX side of MacOS, you may need to access them using the Command+Shift+G key combination.\nMake sure the “Enable version control interface for RStudio projects” button is ticked.\n\n\n\n\n\n\nFigure 2: Mac RStudio Global Options Version Control Dialog Box\n\n\n\nOnce the dialogue box is correct click the Apply button.\n\n\nLinux\nTo be added."
  },
  {
    "objectID": "Tutorial_1-Git,Github,andRStudio.html#let-git-know-who-you-are",
    "href": "Tutorial_1-Git,Github,andRStudio.html#let-git-know-who-you-are",
    "title": "Tutorial 1: Git, Github, and RStudio",
    "section": "Let Git know who you are",
    "text": "Let Git know who you are\nWe need to tell Git who we are, the best way to do this is using the Terminal in RStudio.\nPaste\ngit config --global user.name \"Gary McKeown\"\ngit config --global user.email \"g.mckeown@qub.ac.uk\"\ninto the Terminal, replacing the user.name with your name and the user.email with the email you used to create your GitHub account. Then you can check that this has worked by using the following command.\ngit config --global --list"
  },
  {
    "objectID": "Tutorial_1-Git,Github,andRStudio.html#using-git-within-rstudio",
    "href": "Tutorial_1-Git,Github,andRStudio.html#using-git-within-rstudio",
    "title": "Tutorial 1: Git, Github, and RStudio",
    "section": "Using Git within RStudio",
    "text": "Using Git within RStudio\nRStudio has good integration with Git and for the most part you should be able to do most things while using the RStudio interface. However, the RStudio interface does not implement all of the functionality that Git has; if more functionality is required it is always possible to use the Terminal within RStudio to give Git command line commands to achieve what is desired. The level of use you require will differ depending on the goals you have with Git. There are different workflows depending on your needs and the level of collaboration or product stability you require. For most academics there are often experimentation phases, at some stage there is need for collaboration and collaborative working, and more occasionally there is a requirement for a strong level of permanence and stability. Each of these represent different workflows."
  },
  {
    "objectID": "Tutorial_1-Git,Github,andRStudio.html#connecting-git-to-github",
    "href": "Tutorial_1-Git,Github,andRStudio.html#connecting-git-to-github",
    "title": "Tutorial 1: Git, Github, and RStudio",
    "section": "Connecting Git to GitHub",
    "text": "Connecting Git to GitHub\nGit can function on its own on your local computer as a versioning system to keep track of changes you make to your documents, both saving versions and keeping a log of the changes. However, almost always it is used in conjunction with an online server where you make changes in your local copy of the files and then push those changes to a remote online server somewhere that keeps a version of the files. This allows a version to be made publicly available and it allows multiple collaboartors to work on the same (or multiple) versions of a repository. Clearly one of the challenges that Git is designed to overcome is to keep track of the changes multiple people make in multiple copies of their local files and keep them synced to the main repository. The most popular, but not the only, online server that provides this service is GitHub (GitLab and Bitbucket are other popular alternatives).\n\nPersonal Access Tokens\nRecently GitHub increased their security protocols and now in order to be able to interact with your GitHub a count you need to have a thing called a Personal Access Token that serves as a credential letting GitHub know that you are who you say your are. These replaced passwords as a more secure access method. If you go to the Settings in your GitHub page accessed via the account menu at the top right (Figure 3 (a)). Once in Settings scroll to the bottom where you can see Developer Settings (Figure 3 (b)).\n\n\n\n\n\n\n\n\n\n\n\n(a) GitHub Account Drop Down Menu\n\n\n\n\n\n\n\n\n\n\n\n(b) GitHub Settings Drop Down Menu\n\n\n\n\n\n\n\nFigure 3: Settings Menus\n\n\n\nDeveloper Settings will show you a few options select Personal access tokens and Tokens (classic) and click on Generate new token (Figure 4).\n\n\n\n\n\n\nFigure 4: Personal Access Tokens Page\n\n\n\nYou will be asked to give an expiration date for your Personal Access Token, this is giving you a time when you will need to update this, in essence it is a bit plike providing a date for when you need to change your password. If you are not concerned about security you can choose no expiration date or you can choose custom and put somethign for a year or so in advance. If security is a strong concern then you should get used to changing this regularly.\nWhen it gives the options select “repo”, “user”, and “workflow” (Figure 5, Figure 6).\n\n\n\n\n\n\nFigure 5: Scopes repo and workflow\n\n\n\n\n\n\n\n\n\nFigure 6: Scopes user\n\n\n\nIt will create a token like this:\n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\nThen you should copy it and in the R console install the gitcreds package.\n\ninstall.packages(\"gitcreds\")\n\nOnce you have that installed you can add the line\n\ngitcreds::gitcreds_set()\n\nit will ask you to enter the token and you can paste your token into the console when it asks you to “Enter password or token:”\nYou should now be set up for working with GitHub, using the push and pull commands."
  },
  {
    "objectID": "Tutorial_1-Git,Github,andRStudio.html#joining-github-and-local-git-together",
    "href": "Tutorial_1-Git,Github,andRStudio.html#joining-github-and-local-git-together",
    "title": "Tutorial 1: Git, Github, and RStudio",
    "section": "Joining GitHub and local Git together",
    "text": "Joining GitHub and local Git together\nThe first thing you need to do is to set up a repository. You can do this in two ways you can create a new repository in GitHub and import it to your local machine. The alternative is to create a local repository and send it to GitHub. The former is the easier method and it is the better one to get used to as you will use that method if you are downloading other people’s repositories to collaborate or use their code.\n\nMaking a new repository on GitHub\nClick the big green button to create a new repository (Figure 7).\n\n\n\n\n\n\nFigure 7: Where to create a new repository\n\n\n\nThat will take you on to this page (Figure 8).\n\n\n\n\n\n\nFigure 8: Create a new repository\n\n\n\nGive the repository a name, and a description. Decide whther tyou want to make it public or private—you can change this in the future. Add a README file. in Add .gitignore there are a number of templates that can be used to ignore common files you want to saty in your local repository, but do not upload to the GitHub repository; as I use R a lot I tend to use the R template, it is fine to choose no template though. You can also Choose a license. Initially it is safe to leave this as none, but you may want to inform yourself about the various licenses GitHub makes available. These are the classic software licenses, but they can pertain to open science documents, scientific code, and data too. The new repository will be created a show a page like the one in Figure 9.\n\n\n\n\n\n\nFigure 9: A GitHub Repository Front Page\n\n\n\nIf you press the code button and select the copy button it will copy the necessary URL to the clipboard (Figure 10).\n\n\n\n\n\n\nFigure 10: Where to copy the repo URL\n\n\n\n\n\nMake a local copy of the repository\nThe next step is to make a copy of the repository on your local computer in the directory that you wish to use.\nWithin RStudio go to the File menu and select New Project… this opens the New Project Wizard. Selct Version Control (Figure 11).\n\n\n\n\n\n\nFigure 11: New Project Wizard\n\n\n\nYou are then given the option of two types of version control Subversion and Git. We choose Git (Figure 12).\n\n\n\n\n\n\nFigure 12: New Project Wizard Git Option\n\n\n\nThe last page in this process gives the place to paste in the URL you copied from GitHub (Figure 13).\n\n\n\n\n\n\nFigure 13: New Project GitHub URL\n\n\n\nThe process should then conclude by downloading the repository into the folder/directory that you have requested. You should then have a repository with Git already working and you should be able to commit changes to Git and push and pull then to GitHub. Your local repo is simply a folder/directory in your file, if you wish you can just delete as you would any folder, and start again by doing the process above.\nTo check if it is working you can make a change or add a file and commit it by pressing Commit button in the Git pane. You then select the staged button next to the altered file and add a Commit message—preferably something meaningful. Then hit the Commit button. That updates the changes to the local Git. You will also want to keep things synced with GitHub the remote server, to do this you need to do an additional stage of pushing the changes to GitHub, unsurprisingly, you do this by pressing the Push button in the Git pane. You should also be able to go to the GitHub wensite and check that your changes have now appeared there too."
  },
  {
    "objectID": "open_data.html",
    "href": "open_data.html",
    "title": "Open Data ",
    "section": "",
    "text": "We encourage staff to share their data where appropriate to do so. \n\n\nOpen data supports the inferences and conclusions from our studies and enables others to a) use the data and maximise utility, b) verify our conclusions and promote reproducibility. Sharing data can be facilitated through the PURE repository (preferred). Data may also be shared through the Open Science Framework based at osf.io. Your ethics approvals for your research should guide data sharing, and there is some guidance to support your engagement with Open Science in your ethics application elsewhere in these pages.  \n\n\n\n\nMaximizing transparency to promote reproducibility \nMaximizing usefulness of recorded data for the public good \nReducing the file-drawer phenomenon: increasing efficiency \nIn combination with preregistration it avoids suggestions of benefiting from undisclosed\n\n\n\n\n1. Decide on your licence \nResearchers should apply an open licence to datasets to reduce issues around ambiguity and what can and cannot be done with the shared data . This licence is most often a specified Creative Commons licence (click on the link to identify the right licence for you). Please note without a licence it can be used without credit or acknowledgement of the source. PURE colleagues are also very helpful if you need advice about any of this.\n2. Observe the guidelines on data deposit \nThe guidelines on data deposit at Queen’s University Belfast (available at Standard Operating Procedures). Further support on Research Data Management is available from the library / Open Research Team.  \nKey publications include: \nSetting Up, Maintaining and Archiving Research Files and  \nData Management, Collection, Validation and Storage\n3. Make sure the data is suitable for deposit using FAIR principles \nFAIR principles should be applied. Data should be \nFindable – data should have a Digital Object Identifier (DOI) which allows it to be easily found using search tools. \nAccessible – data should be accessible to others and deposited on a credible repository. \nInteroperable – data formats should be adaptable to multiple analytical platforms for future use. We recommend the use of .csv format to support use by others. \nReusable – data should be clearly labelled with an accompanying licence (often CC BY 4.0, but for more information see the creative commons licences links above).  \nFAIR principles should motivate us to organize the data logically and accompany it by documentation. Importantly, with data accessibility in mind, many of these aspects can be planned for in the data management plan to minimize the time needed, while maximizing the benefits.\n4. Link manuscript with your data \nUse the DOI in your manuscript as you submit to a journal to illustrate where your data is sourced. You may also want to do this with your Open Materials.\n5. Set access rules and encourage others to engage with your work \nYou can put an embargo on the date at which data can be accessed such as 12 months from deposit to allow you to publish the papers you wish from the data, and still leave it available for others to access. You may also wish to put out a statement regarding re-use of the data: \nData may be used without express permission from the authors if the following conditions are met.  \nPlease cite the source of the data as: \nJones, A.B. (2022). Name of the dataset from the PURE deposit [Data set]. Queen’s University Belfast. https://doi.org/01234.5678910  \nJones, A.B. (2022). First paper describing the results of the name of the dataset from the PURE deposit. Journal of Open Science Research. 1(2), 101-102. https://doi.org/10.01234.5678910 \nPlease contact the lead author, Professor Jones (ab.jones@qub.ac.uk),) with any publications arising from the data.\n\n\n\nWithin the university, Open data is supported by the Open Research Team. They can help with producing Data Management Plans, which are required by most funders, obtaining DOIs, and with getting access to the Active Data Storage (ADS) service for large datasets. If you have any questions about these aspects, get in touch with rdm@qub.ac.uk.\n\n\n\nThere are many ways to make data open. QUB offers researchers to share their research data through PURE (https://pure.qub.ac.uk/en/datasets/), or through the aforementioned Active Data Storage service. Some QUB Psychology data is being shared through the following portals:\nOpen Science Framework \n\nPlatform dedicated to Open Science. \nMultiple server locations \nExamples: Reid and Dessing (2018), Schultze, Gerlach and Rittich (2017)]  \n\nZenodo \n\nServers based at CERN \n\nBeyond that, the following online data repositories are frequently used in our field: \nResearch Box  \n\nMirroring AsPredicted.org\nData and materials archive\n\nFor an overview of different online data repositories, see https://www.re3data.org/\n\n\n\nShould all data be shared? \nNo. A commonly used phrasing is “Be as open as possible, as closed as necessary”. If you cannot anonymize your data, sharing may not be possible (unless explicitly consented by the participants). Moreover, sharing of data (or materials) may be constrained by considerations of intellectual property.  \nIs it extra work? \nYes. Many of the repositories require creating an account. Moreover, while uploading data nowadays typically is a drag-and-drop exercise, proper organization of the data using FAIR principles will take some time."
  },
  {
    "objectID": "open_data.html#what-is-open-data",
    "href": "open_data.html#what-is-open-data",
    "title": "Open Data ",
    "section": "",
    "text": "Open data supports the inferences and conclusions from our studies and enables others to a) use the data and maximise utility, b) verify our conclusions and promote reproducibility. Sharing data can be facilitated through the PURE repository (preferred). Data may also be shared through the Open Science Framework based at osf.io. Your ethics approvals for your research should guide data sharing, and there is some guidance to support your engagement with Open Science in your ethics application elsewhere in these pages."
  },
  {
    "objectID": "open_data.html#what-are-the-benefits-of-open-data",
    "href": "open_data.html#what-are-the-benefits-of-open-data",
    "title": "Open Data ",
    "section": "",
    "text": "Maximizing transparency to promote reproducibility \nMaximizing usefulness of recorded data for the public good \nReducing the file-drawer phenomenon: increasing efficiency \nIn combination with preregistration it avoids suggestions of benefiting from undisclosed"
  },
  {
    "objectID": "open_data.html#how-to-deposit-and-curate-your-data",
    "href": "open_data.html#how-to-deposit-and-curate-your-data",
    "title": "Open Data ",
    "section": "",
    "text": "1. Decide on your licence \nResearchers should apply an open licence to datasets to reduce issues around ambiguity and what can and cannot be done with the shared data . This licence is most often a specified Creative Commons licence (click on the link to identify the right licence for you). Please note without a licence it can be used without credit or acknowledgement of the source. PURE colleagues are also very helpful if you need advice about any of this.\n2. Observe the guidelines on data deposit \nThe guidelines on data deposit at Queen’s University Belfast (available at Standard Operating Procedures). Further support on Research Data Management is available from the library / Open Research Team.  \nKey publications include: \nSetting Up, Maintaining and Archiving Research Files and  \nData Management, Collection, Validation and Storage\n3. Make sure the data is suitable for deposit using FAIR principles \nFAIR principles should be applied. Data should be \nFindable – data should have a Digital Object Identifier (DOI) which allows it to be easily found using search tools. \nAccessible – data should be accessible to others and deposited on a credible repository. \nInteroperable – data formats should be adaptable to multiple analytical platforms for future use. We recommend the use of .csv format to support use by others. \nReusable – data should be clearly labelled with an accompanying licence (often CC BY 4.0, but for more information see the creative commons licences links above).  \nFAIR principles should motivate us to organize the data logically and accompany it by documentation. Importantly, with data accessibility in mind, many of these aspects can be planned for in the data management plan to minimize the time needed, while maximizing the benefits.\n4. Link manuscript with your data \nUse the DOI in your manuscript as you submit to a journal to illustrate where your data is sourced. You may also want to do this with your Open Materials.\n5. Set access rules and encourage others to engage with your work \nYou can put an embargo on the date at which data can be accessed such as 12 months from deposit to allow you to publish the papers you wish from the data, and still leave it available for others to access. You may also wish to put out a statement regarding re-use of the data: \nData may be used without express permission from the authors if the following conditions are met.  \nPlease cite the source of the data as: \nJones, A.B. (2022). Name of the dataset from the PURE deposit [Data set]. Queen’s University Belfast. https://doi.org/01234.5678910  \nJones, A.B. (2022). First paper describing the results of the name of the dataset from the PURE deposit. Journal of Open Science Research. 1(2), 101-102. https://doi.org/10.01234.5678910 \nPlease contact the lead author, Professor Jones (ab.jones@qub.ac.uk),) with any publications arising from the data."
  },
  {
    "objectID": "open_data.html#where-to-get-help",
    "href": "open_data.html#where-to-get-help",
    "title": "Open Data ",
    "section": "",
    "text": "Within the university, Open data is supported by the Open Research Team. They can help with producing Data Management Plans, which are required by most funders, obtaining DOIs, and with getting access to the Active Data Storage (ADS) service for large datasets. If you have any questions about these aspects, get in touch with rdm@qub.ac.uk."
  },
  {
    "objectID": "open_data.html#where-to-share-data",
    "href": "open_data.html#where-to-share-data",
    "title": "Open Data ",
    "section": "",
    "text": "There are many ways to make data open. QUB offers researchers to share their research data through PURE (https://pure.qub.ac.uk/en/datasets/), or through the aforementioned Active Data Storage service. Some QUB Psychology data is being shared through the following portals:\nOpen Science Framework \n\nPlatform dedicated to Open Science. \nMultiple server locations \nExamples: Reid and Dessing (2018), Schultze, Gerlach and Rittich (2017)]  \n\nZenodo \n\nServers based at CERN \n\nBeyond that, the following online data repositories are frequently used in our field: \nResearch Box  \n\nMirroring AsPredicted.org\nData and materials archive\n\nFor an overview of different online data repositories, see https://www.re3data.org/"
  },
  {
    "objectID": "open_data.html#common-questions",
    "href": "open_data.html#common-questions",
    "title": "Open Data ",
    "section": "",
    "text": "Should all data be shared? \nNo. A commonly used phrasing is “Be as open as possible, as closed as necessary”. If you cannot anonymize your data, sharing may not be possible (unless explicitly consented by the participants). Moreover, sharing of data (or materials) may be constrained by considerations of intellectual property.  \nIs it extra work? \nYes. Many of the repositories require creating an account. Moreover, while uploading data nowadays typically is a drag-and-drop exercise, proper organization of the data using FAIR principles will take some time."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Principles ",
    "section": "",
    "text": "These guidelines will support staff of the School of Psychology, Queen’s University Belfast, in their efforts to engage in Open Science practices, now considered to be at the cutting edge of our discipline. We aim to inspire staff to engage with Open Science; we should all aspire to adopt Open Science practices. Over time, these may well become requirements (e.g., from publishers, funders, REF), but it makes sense to anticipate this. These guidelines and Open Science in general are governed by several principles. \n\n\nThese Open Science guidelines are written as an accessible guide to Open Science for academic and research staff in the School of Psychology. However, they should also be helpful for professional service staff and students. In the spirit of Open Science, the guidelines are available for all including those from outside the institution. The following guide is a living document, which will be continually updated to keep the information aligned with advances in Open Science, so it is best to refer to the most current version of the guidelines. \n\n\n\nOpen Science emphasises transparency and integrity in accurate and truthful reporting of science. Being open and transparent at all stages and all levels of the scientific process improves all scientific fields. The principles and proposed practices of Open Science serve to expand the accessibility and inclusivity of research and the knowledge it creates. By making data, analysis methods, and other research materials available to all through online repositories, many of the barriers to participation in science for those outside of elite academic institutions are removed. In this sense, Open Science principles are aligned to enhancing equity in science and expanding the diversity of future research as a result. \n\n\n\nOpen Science directly addresses the ‘replication crisis’ initially identified in the field of Psychology. The replication crisis happened because scientists  were incentivised (by the academic reward structure) to report results that often failed to replicate (e.g., ‘false positives’). Open Science is a mindset to do what is right for science, to strive for  \n- transparency of motivations, methods and inferences  \n- reproducibility of scientific methods  \n- robustness of patterns (i.e., replicability) \nOpen Science emphasises transparency and integrity in accurate and truthful reporting of science. Being open and transparent at all stages and all levels of the scientific process improves all scientific fields.  \nThere is an increasing recognition of the value of Open Science practices proposed to fulfil these aims. Indeed, engagement with Open Science is being embedded in criteria for 1) open access publishing in high impact journals, 2) research funding, especially by national and international funders 3) the Research Excellent Framework, 4) academic job descriptions and progression and 5) Higher Education teaching curricula. \n\n\n\nTo help embed Open Science within the research culture of the School of Psychology, this guide will provide descriptions and practical advice on key Open Science practices: Preregistration, Ethics and Open Science, Open data, Open materials, Open-source formats, Reproducible Documents, Open-Access Publishing and Education. \n\n\n\nThis document is written by your colleagues to support the School’s efforts to be more engaged in open science practices. If you spot any errors, would like to add any amendments, or have an innovation or efficient practice to share, please fill out the Open Science Webform.\nIf you require any advice or support regarding your Open Science practice feel free to contact the authors at \nJoost Dessing j.dessing@qub.ac.uk \nLisa Graham-Wisener l.grahamwisener@qub.ac.uk  \nGary McKeown g.mckeown@qub.ac.uk  \nPaul Toner p.toner@qub.ac.uk  \nMartin Robinson p.toner@qub.ac.uk\nBethan Iley biley01@qub.ac.uk\nMatthew Rodger m.rodger@qub.ac.uk \nGillian Shorter g.shorter@qub.ac.uk \nTanja Gerlach t.gerlach@qub.ac.uk \nThomas Schultze-Gerlach t.schultze@qub.ac.uk"
  },
  {
    "objectID": "intro.html#kindness",
    "href": "intro.html#kindness",
    "title": "Principles ",
    "section": "",
    "text": "These Open Science guidelines are written as an accessible guide to Open Science for academic and research staff in the School of Psychology. However, they should also be helpful for professional service staff and students. In the spirit of Open Science, the guidelines are available for all including those from outside the institution. The following guide is a living document, which will be continually updated to keep the information aligned with advances in Open Science, so it is best to refer to the most current version of the guidelines."
  },
  {
    "objectID": "intro.html#equity-and-diversity",
    "href": "intro.html#equity-and-diversity",
    "title": "Principles ",
    "section": "",
    "text": "Open Science emphasises transparency and integrity in accurate and truthful reporting of science. Being open and transparent at all stages and all levels of the scientific process improves all scientific fields. The principles and proposed practices of Open Science serve to expand the accessibility and inclusivity of research and the knowledge it creates. By making data, analysis methods, and other research materials available to all through online repositories, many of the barriers to participation in science for those outside of elite academic institutions are removed. In this sense, Open Science principles are aligned to enhancing equity in science and expanding the diversity of future research as a result."
  },
  {
    "objectID": "intro.html#why-is-open-science-important",
    "href": "intro.html#why-is-open-science-important",
    "title": "Principles ",
    "section": "",
    "text": "Open Science directly addresses the ‘replication crisis’ initially identified in the field of Psychology. The replication crisis happened because scientists  were incentivised (by the academic reward structure) to report results that often failed to replicate (e.g., ‘false positives’). Open Science is a mindset to do what is right for science, to strive for  \n- transparency of motivations, methods and inferences  \n- reproducibility of scientific methods  \n- robustness of patterns (i.e., replicability) \nOpen Science emphasises transparency and integrity in accurate and truthful reporting of science. Being open and transparent at all stages and all levels of the scientific process improves all scientific fields.  \nThere is an increasing recognition of the value of Open Science practices proposed to fulfil these aims. Indeed, engagement with Open Science is being embedded in criteria for 1) open access publishing in high impact journals, 2) research funding, especially by national and international funders 3) the Research Excellent Framework, 4) academic job descriptions and progression and 5) Higher Education teaching curricula."
  },
  {
    "objectID": "intro.html#open-science-practices",
    "href": "intro.html#open-science-practices",
    "title": "Principles ",
    "section": "",
    "text": "To help embed Open Science within the research culture of the School of Psychology, this guide will provide descriptions and practical advice on key Open Science practices: Preregistration, Ethics and Open Science, Open data, Open materials, Open-source formats, Reproducible Documents, Open-Access Publishing and Education."
  },
  {
    "objectID": "intro.html#feedback-and-additional-information",
    "href": "intro.html#feedback-and-additional-information",
    "title": "Principles ",
    "section": "",
    "text": "This document is written by your colleagues to support the School’s efforts to be more engaged in open science practices. If you spot any errors, would like to add any amendments, or have an innovation or efficient practice to share, please fill out the Open Science Webform.\nIf you require any advice or support regarding your Open Science practice feel free to contact the authors at \nJoost Dessing j.dessing@qub.ac.uk \nLisa Graham-Wisener l.grahamwisener@qub.ac.uk  \nGary McKeown g.mckeown@qub.ac.uk  \nPaul Toner p.toner@qub.ac.uk  \nMartin Robinson p.toner@qub.ac.uk\nBethan Iley biley01@qub.ac.uk\nMatthew Rodger m.rodger@qub.ac.uk \nGillian Shorter g.shorter@qub.ac.uk \nTanja Gerlach t.gerlach@qub.ac.uk \nThomas Schultze-Gerlach t.schultze@qub.ac.uk"
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "Ethics and Open Science ",
    "section": "",
    "text": "Ethics and Open Science \nIn order to engage with Open Science practices, you must consider some ethical issues that apply to your work. There are three key considerations: \n\nBeing clear with participants at the time of collection about what you plan to use the research data for \n\nMake sure that your participant information sheet and consent form inform participants that their anonymised data will be made available to the general public via the internet. Participants should consent to their anonymised data being freely shared. Not providing this information technically precludes the sharing of data files with others in any form. Therefore, language such as below should be included in the participant information sheet and consent form: \nInformation sheet\nBecause the data we collect from you may be of interest to other researchers, we will publish it on a publicly accessible online data repository. At that point, anyone will have access to your data. However, this only concerns fully anonymised information that cannot identify you, and we will only do this with your permission (please confirm this on the consent form). \nConsent form \nI understand that data from this study may be of interest to other researchers. I consent for my non-identifiable data to be shared through a publicly accessible online data repository. I know that even if I do not consent to this, I can still participate. \nIf the dataset contains any identifying information, you should also specify how participants can withdraw their consent for sharing this data at any time in the future: \nI know I can opt out of this at any time in the future by contacting xxxx, quoting my personal ID number. \n\nAnonymity of data and protecting the identity of your participants\n\nIf data cannot be anonymized and shared, a solution can be sharing metadata (a summary of the data, such as group means, standard deviations, effect sizes, a table with zero-order correlations between all study variables, etc.). Metadata should be richly described and contain accurate and relevant attributes. Clear indication of who generated the metadata should also be included. Signposting for data that is available by request only may also be appropriate.\nData can be anonymous – with no identifiers – or confidential – with some information that can identify individuals which should be kept according to data protection legislation. All data should be kept according to the permissions we have sought and been granted by the participants or data custodians. \nWhen data is confidential, such that it has some clearly identifiable information (e.g., addresses, names, postcodes, places, or other identifiers), much of this can be removed before data deposit or replaced with a unique identifier in the case of data that is linked over time. Where data requires anonymising before deposit, two individuals should independently inspect the dataset to remove any identifiable information or recode information in a standardised way as to minimise the risk of identification. Particular care should be given to the following: \n\nInformation including names, addresses, demographic information, place names, specific instances, dates of birth, etc.: remove or systematically recode. \nTextual information which may refer to or identify information or people: consider appropriate recoding which keeps meaning without identifying a person or situation. \nNumeric information which has a frequency of less than five which may identify an individual: consider collapsing categories down, depending on whether it is meaningful, or recode to a blank other. \n\nFor anonymous data that do not include any identifying information as standard, data should be checked for low frequency items which may need to be recoded as other or open questions should also be inspected for identifying information regarding self or others by one person before deposit.  \n\nRespecting the wishes of those who take part in research \n\nA commonly used phrasing is “Be as open as possible, as closed as necessary”. Individuals should not be excluded from research participation if they would not like their information shared. \nFor a more extensive treatment of ethical considerations and practical tips regarding data sharing, see Meyer (2018). \n\n\n\n\n\nReferences\n\nMeyer, M. N. (2018). Practical tips for ethical data sharing. Advances in Methods and Practices in Psychological Science, 1(1), 131–144. https://doi.org/10.1177/2515245917747656"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIn summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "open-access_publishing.html",
    "href": "open-access_publishing.html",
    "title": "Open-Access Publishing",
    "section": "",
    "text": "We encourage staff to publish open-access where possible and appropriate to do so \n\n\nOpen Access publishing refers to making research publications freely available to anyone who would want to access them, including the public. Traditionally, access to publications has been hidden behind a publisher paywall, meaning access is limited to those with a library subscription or those who can afford the access fee. By publishing open access, any financial, legal, and technical barriers to accessing a publication are removed. There are different levels of open access publishing.\nOpen Access publishing includes Green, Gold, and Diamond pathways that refers to publishing in a traditional journal and sharing a version of the article (generally a preprint or postprint) in a subject or institutional repository. Green Open Access includes making previously published works freely available, Gold Open Access ss refers to the publishing works in a format free to readers, whereas Diamond Open Access is entirely free in dissemination: for authors and readers.\n\n\n\n\nMaximising the international visibility and reach of research, across both High-Income and Low-to-Middle-Income countries\nMaximising the usefulness and impact of research to influence policy and practice\nMaximising the value of publicly funded research to the taxpayer\n\n\n\n\nThe Open Research team are available to advise on all aspects of open access publishing (https://libguides.qub.ac.uk/openaccess/introduction) and have several open access agreements with publishers, e.g. a fee waiver for Gold open access publishing with journals.\nIf you are not publishing in a Gold open access journal, QUB encourages researchers to share their publications at the earliest opportunity following publication. The nature of what is deposited and when this can be shared will depend on the publisher. The Sherpa Romeo link below provides guidance on what you need to make available.\nCORE\n\nThe largest aggregator of open access research papers in the world\n\nDirectory of Open Access Journals (DOAJ)\n\nA directory of Open Access Journals\n\nPsyArxiv\n\nA free preprint service for the psychological sciences\n\nSherpa Romeo\nAn online resource that provides summaries of publisher copyright and open access archiving policies on a journal-by-journal basis. It will also provide information on whether your journal supports pre-prints and what version of the manuscript is supported for PURE deposits.\n\n\n\nShould all publications be open access?\nIncreasingly, research funders (e.g., UKRI) require publications to be open access and articles are also required to be open access for REF eligibility. If deciding not to publish open access, it is worth taking this into consideration. Ultimately it is important that your work appears before the most appropriate audience.\nIs it extra work?\nYes and no. The decision to publish open access can be incorporated into your decision-making process on where to publish. If publishing Green open access, there is a small amount of work involved in uploading the appropriate document version to a repository.  If you are unsure of where to publish it might be useful to use the a search engine such as Jane to narrow the field and/or seek advice."
  },
  {
    "objectID": "open-access_publishing.html#what-is-open-access-publishing",
    "href": "open-access_publishing.html#what-is-open-access-publishing",
    "title": "Open-Access Publishing",
    "section": "",
    "text": "Open Access publishing refers to making research publications freely available to anyone who would want to access them, including the public. Traditionally, access to publications has been hidden behind a publisher paywall, meaning access is limited to those with a library subscription or those who can afford the access fee. By publishing open access, any financial, legal, and technical barriers to accessing a publication are removed. There are different levels of open access publishing.\nOpen Access publishing includes Green, Gold, and Diamond pathways that refers to publishing in a traditional journal and sharing a version of the article (generally a preprint or postprint) in a subject or institutional repository. Green Open Access includes making previously published works freely available, Gold Open Access ss refers to the publishing works in a format free to readers, whereas Diamond Open Access is entirely free in dissemination: for authors and readers."
  },
  {
    "objectID": "open-access_publishing.html#benefits",
    "href": "open-access_publishing.html#benefits",
    "title": "Open-Access Publishing",
    "section": "",
    "text": "Maximising the international visibility and reach of research, across both High-Income and Low-to-Middle-Income countries\nMaximising the usefulness and impact of research to influence policy and practice\nMaximising the value of publicly funded research to the taxpayer"
  },
  {
    "objectID": "open-access_publishing.html#where-to-publish-open-access",
    "href": "open-access_publishing.html#where-to-publish-open-access",
    "title": "Open-Access Publishing",
    "section": "",
    "text": "The Open Research team are available to advise on all aspects of open access publishing (https://libguides.qub.ac.uk/openaccess/introduction) and have several open access agreements with publishers, e.g. a fee waiver for Gold open access publishing with journals.\nIf you are not publishing in a Gold open access journal, QUB encourages researchers to share their publications at the earliest opportunity following publication. The nature of what is deposited and when this can be shared will depend on the publisher. The Sherpa Romeo link below provides guidance on what you need to make available.\nCORE\n\nThe largest aggregator of open access research papers in the world\n\nDirectory of Open Access Journals (DOAJ)\n\nA directory of Open Access Journals\n\nPsyArxiv\n\nA free preprint service for the psychological sciences\n\nSherpa Romeo\nAn online resource that provides summaries of publisher copyright and open access archiving policies on a journal-by-journal basis. It will also provide information on whether your journal supports pre-prints and what version of the manuscript is supported for PURE deposits."
  },
  {
    "objectID": "open-access_publishing.html#common-questions",
    "href": "open-access_publishing.html#common-questions",
    "title": "Open-Access Publishing",
    "section": "",
    "text": "Should all publications be open access?\nIncreasingly, research funders (e.g., UKRI) require publications to be open access and articles are also required to be open access for REF eligibility. If deciding not to publish open access, it is worth taking this into consideration. Ultimately it is important that your work appears before the most appropriate audience.\nIs it extra work?\nYes and no. The decision to publish open access can be incorporated into your decision-making process on where to publish. If publishing Green open access, there is a small amount of work involved in uploading the appropriate document version to a repository.  If you are unsure of where to publish it might be useful to use the a search engine such as Jane to narrow the field and/or seek advice."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "These guidelines are licensed under the Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) license.\n\nYou are free to:\n\nShare — copy and redistribute the material in any medium or format\nAdapt — remix, transform, and build upon the material for any purpose, even commercially.\nThe licensor cannot revoke these freedoms as long as you follow the license terms.\n\n\n\nUnder the following terms:\n\nAttribution — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\nShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.\nNo additional restrictions — You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits."
  },
  {
    "objectID": "open_source_formats.html",
    "href": "open_source_formats.html",
    "title": "Open-Source formats",
    "section": "",
    "text": "Much of science relies on computers and software. Many of the traditionally used software is commercial and thus requires a license. The cost for such licenses is a barrier to opening science, since not all institutes or labs will be able to afford the same licenses. This means some researchers might not be able to verify the conclusions of others, or benefit from their shared materials. The use of Open-Source formats aims to prevent this and contribute to data being interoperable (see Open Data). This involves ensuring data is shared in formats accessible by Open-source software, which can of course be achieved by using Open-source software as much possible throughout the research process.\n\n\n\n\nMaximizing reproducibility\nMaximizing usefulness of materials contributing to science and its progress\n\n\n\n\nThis is largely based on personal initiative. Search for Open Source variants of software you are using and decide whether and how these could replace your current proprietary software. Sometimes, a full switch to using a new software is the best solution; the School is currently starting the process of switching from using SPSS to using R-based software for statistical analyses. In some cases, sharing data or materials from proprietary software in formats that can be read by or executed by (e.g., computer code) by Open Source variants is the easiest solution. Of course, in line with FAIR principles you ideally confirm that the Open Source software indeed works for your materials. In this light, it is appropriate to report the software version for which you confirmed this.\nIndeed, citing the software and packages you used is important, both from a reproducibility perspective but also as a way to acknowledge the work and time that people spent creating tools for others. Ideally, you would also include version numbers here. Please see below for an example:\nAll statistical analyses were run using R 3.3.2 (https://www.r-project.org; R Core Team, 2016). In addition to the base version of R, we used the packages dplyr 0.5.0 (Wickham, 2011), effsize 0.7.0 (Torchiano, 2016), ggplot2 2.2.0 (Wickham, 2009), Hmisc 4.0–1 (Harrell, 2016), lm.beta 1.5–1 (Behrendt, 2014), multicon 1.6 (Sherman, 2015), psych 1.6.9 (Revelle, 2016), and yarrr 0.1.2 (Phillips, 2016) in our analyses."
  },
  {
    "objectID": "open_source_formats.html#what-are-open-source-formats",
    "href": "open_source_formats.html#what-are-open-source-formats",
    "title": "Open-Source formats",
    "section": "",
    "text": "Much of science relies on computers and software. Many of the traditionally used software is commercial and thus requires a license. The cost for such licenses is a barrier to opening science, since not all institutes or labs will be able to afford the same licenses. This means some researchers might not be able to verify the conclusions of others, or benefit from their shared materials. The use of Open-Source formats aims to prevent this and contribute to data being interoperable (see Open Data). This involves ensuring data is shared in formats accessible by Open-source software, which can of course be achieved by using Open-source software as much possible throughout the research process."
  },
  {
    "objectID": "open_source_formats.html#benefits-of-open-source-formats",
    "href": "open_source_formats.html#benefits-of-open-source-formats",
    "title": "Open-Source formats",
    "section": "",
    "text": "Maximizing reproducibility\nMaximizing usefulness of materials contributing to science and its progress"
  },
  {
    "objectID": "open_source_formats.html#how-to-engage",
    "href": "open_source_formats.html#how-to-engage",
    "title": "Open-Source formats",
    "section": "",
    "text": "This is largely based on personal initiative. Search for Open Source variants of software you are using and decide whether and how these could replace your current proprietary software. Sometimes, a full switch to using a new software is the best solution; the School is currently starting the process of switching from using SPSS to using R-based software for statistical analyses. In some cases, sharing data or materials from proprietary software in formats that can be read by or executed by (e.g., computer code) by Open Source variants is the easiest solution. Of course, in line with FAIR principles you ideally confirm that the Open Source software indeed works for your materials. In this light, it is appropriate to report the software version for which you confirmed this.\nIndeed, citing the software and packages you used is important, both from a reproducibility perspective but also as a way to acknowledge the work and time that people spent creating tools for others. Ideally, you would also include version numbers here. Please see below for an example:\nAll statistical analyses were run using R 3.3.2 (https://www.r-project.org; R Core Team, 2016). In addition to the base version of R, we used the packages dplyr 0.5.0 (Wickham, 2011), effsize 0.7.0 (Torchiano, 2016), ggplot2 2.2.0 (Wickham, 2009), Hmisc 4.0–1 (Harrell, 2016), lm.beta 1.5–1 (Behrendt, 2014), multicon 1.6 (Sherman, 2015), psych 1.6.9 (Revelle, 2016), and yarrr 0.1.2 (Phillips, 2016) in our analyses."
  },
  {
    "objectID": "preprinting.html",
    "href": "preprinting.html",
    "title": "Preprinting",
    "section": "",
    "text": "Article preprinting is a part of an Open Access publication strategy that may be useful to share and receive feedback on findings quickly, and where Gold Open Access sharing of outputs is not feasible (see Sherpa Romeo). Many publishers will allow for the author submitted manuscript version to archived in a repository, but you may consider preprinting a manuscript: a complete draft of a research paper shared prior to peer review and publication.\n\n\n\n\nLack of Peer Review: Perhaps the main criticism of preprints, and a concern reported by authors, is the absence of formal peer review. The peer review process is crucial in ensuring the quality and reliability of published research. One may be concerned that dissemination without following this process risks sharing flawed or incomplete research.\nQuality Control: Sharing of this flawed or misguided research can lead to the spread of misinformation. Readers might not differentiate between high-quality, peer-reviewed articles and flawed preprints, particularily as more and more research becomes available through preprint repositories. There can also be substantive changes to a manuscript through peer-review, and if not properly indexed by the preprint could lead to confusion and misguided decisions.\nCitation: Researchers might be discouraged to cite preprints in their own work due to the lack of peer review or concerns about quality, so authors might worry what’s the use in sharing? Similarly if an article is featured as a preprint and peer-reviewed publication there may be concerns about properly capturing all indexing and citations of that work.\nEarly Visibility: Authors may also worry about valuable ideas being scooped or iterated before they have had a chance to publish peer-reviewed outputs form their research. This can lead not only to stolen work and ideas, but less impact for one’s own original research.\nImpact on Journal Submissions: Some publishers have policies that seem to discourage submissions previously disseminated as preprints. Researchers may worry about the implication of sharing their work as a preprint, and if this limits their future avenues for publication.\n\n\n\n\n\nLack of Peer Review: Preprint sharing allows researchers to share their findings with their peers and the public more quickly that traditional publication routes. This can be a particular advantage as the peer-review process is noted to be increasingly lengthy and frustrating to researchers. Rapid dissemination of knowledge can facilitate quicker collaboration and innovation among researchers.\nQuality Control: Preprint sharing allows peers to openly review and discuss work, leading to more equitable quality assurance. Preprint services such as Research Square prominently warn that results are not peer-reviewed and should be used with caution, and allow for open review from readers and journal appointed peer-reviewers, making the process more transparent.\nCitation: Preprint articles can show a commitment to Open Access of research, and are usually freely accessible to anyone with an internet connection. This open access model promotes more recognition for researchers and with the ability to mint DOI’s for preprints via established repositories allows these projects to be indexed and cited to recognise the work and prevent scooping of research ideas.\nEarly Visibility: Preprint sharing can increase recognition of researchers and their work, especially for early-career researchers as they establish their profile and presence in a field of research. Sharing timestamped article preprints and featuring these on a CV can help showcase work that is in the pipeline without risking research ideas being stolen by others, and importantly provide tangible record of achievement in applications. This can allow for review and exchange with the academic community before and during the publication process, ultimately benefiting their network and research. Evidence has also shown that articles shared as a preprint are associated with greater engagement and citation.\nImpact on Journal Submission: While some publishers may be hesitant to received submissions shared as pre-print articles this is becoming increasingly rare. Large publishers such BMC have specifically clarified that preprinting an article does not constitute duplicate publication, and in fact may facilitate preprinting articles under review via Research Square.\n\n\n\n\n\n\nThe main advantages of preprint sharing identified by researchers are making research communication more rapid and more equitable, removing barriers in the way of innovation and application. Researchers may worry about misinformation and premature media coverage from their work, or that preprinting carries with it the criticisms of predatory publishing: allowing the dissemination of unscrutinised work. Nevertheless, responsible use of preprint sharing where authors and publishers adhere to standards of academic integrity can allow for more advantageous  and open science practice."
  },
  {
    "objectID": "preprinting.html#what-is-preprinting",
    "href": "preprinting.html#what-is-preprinting",
    "title": "Preprinting",
    "section": "",
    "text": "Article preprinting is a part of an Open Access publication strategy that may be useful to share and receive feedback on findings quickly, and where Gold Open Access sharing of outputs is not feasible (see Sherpa Romeo). Many publishers will allow for the author submitted manuscript version to archived in a repository, but you may consider preprinting a manuscript: a complete draft of a research paper shared prior to peer review and publication."
  },
  {
    "objectID": "preprinting.html#why-wouldnt-i-preprint-my-manuscript",
    "href": "preprinting.html#why-wouldnt-i-preprint-my-manuscript",
    "title": "Preprinting",
    "section": "",
    "text": "Lack of Peer Review: Perhaps the main criticism of preprints, and a concern reported by authors, is the absence of formal peer review. The peer review process is crucial in ensuring the quality and reliability of published research. One may be concerned that dissemination without following this process risks sharing flawed or incomplete research.\nQuality Control: Sharing of this flawed or misguided research can lead to the spread of misinformation. Readers might not differentiate between high-quality, peer-reviewed articles and flawed preprints, particularily as more and more research becomes available through preprint repositories. There can also be substantive changes to a manuscript through peer-review, and if not properly indexed by the preprint could lead to confusion and misguided decisions.\nCitation: Researchers might be discouraged to cite preprints in their own work due to the lack of peer review or concerns about quality, so authors might worry what’s the use in sharing? Similarly if an article is featured as a preprint and peer-reviewed publication there may be concerns about properly capturing all indexing and citations of that work.\nEarly Visibility: Authors may also worry about valuable ideas being scooped or iterated before they have had a chance to publish peer-reviewed outputs form their research. This can lead not only to stolen work and ideas, but less impact for one’s own original research.\nImpact on Journal Submissions: Some publishers have policies that seem to discourage submissions previously disseminated as preprints. Researchers may worry about the implication of sharing their work as a preprint, and if this limits their future avenues for publication."
  },
  {
    "objectID": "preprinting.html#why-would-i-pre-print-my-manuscript",
    "href": "preprinting.html#why-would-i-pre-print-my-manuscript",
    "title": "Preprinting",
    "section": "",
    "text": "Lack of Peer Review: Preprint sharing allows researchers to share their findings with their peers and the public more quickly that traditional publication routes. This can be a particular advantage as the peer-review process is noted to be increasingly lengthy and frustrating to researchers. Rapid dissemination of knowledge can facilitate quicker collaboration and innovation among researchers.\nQuality Control: Preprint sharing allows peers to openly review and discuss work, leading to more equitable quality assurance. Preprint services such as Research Square prominently warn that results are not peer-reviewed and should be used with caution, and allow for open review from readers and journal appointed peer-reviewers, making the process more transparent.\nCitation: Preprint articles can show a commitment to Open Access of research, and are usually freely accessible to anyone with an internet connection. This open access model promotes more recognition for researchers and with the ability to mint DOI’s for preprints via established repositories allows these projects to be indexed and cited to recognise the work and prevent scooping of research ideas.\nEarly Visibility: Preprint sharing can increase recognition of researchers and their work, especially for early-career researchers as they establish their profile and presence in a field of research. Sharing timestamped article preprints and featuring these on a CV can help showcase work that is in the pipeline without risking research ideas being stolen by others, and importantly provide tangible record of achievement in applications. This can allow for review and exchange with the academic community before and during the publication process, ultimately benefiting their network and research. Evidence has also shown that articles shared as a preprint are associated with greater engagement and citation.\nImpact on Journal Submission: While some publishers may be hesitant to received submissions shared as pre-print articles this is becoming increasingly rare. Large publishers such BMC have specifically clarified that preprinting an article does not constitute duplicate publication, and in fact may facilitate preprinting articles under review via Research Square."
  },
  {
    "objectID": "preprinting.html#should-i-preprint-my-manuscript",
    "href": "preprinting.html#should-i-preprint-my-manuscript",
    "title": "Preprinting",
    "section": "",
    "text": "The main advantages of preprint sharing identified by researchers are making research communication more rapid and more equitable, removing barriers in the way of innovation and application. Researchers may worry about misinformation and premature media coverage from their work, or that preprinting carries with it the criticisms of predatory publishing: allowing the dissemination of unscrutinised work. Nevertheless, responsible use of preprint sharing where authors and publishers adhere to standards of academic integrity can allow for more advantageous  and open science practice."
  }
]